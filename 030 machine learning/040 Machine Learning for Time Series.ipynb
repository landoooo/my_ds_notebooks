{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f137595-b79a-4f1c-a389-5a0eab6c77a3",
   "metadata": {},
   "source": [
    "> THIS NOTEBOOK SHOULD BE UPDATED. THERE IS A LOT OF MISSING THINGS\n",
    "\n",
    "# Machine learning for Time Series Data\n",
    "\n",
    "The dataset we are going to use comes from:\n",
    "- Heartbeat wave: https://www.kaggle.com/datasets/kinguistics/heartbeat-sounds/\n",
    "- Stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440702bf-7edd-48a9-89cb-bee094f38482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from glob import glob\n",
    "import librosa as lr \n",
    "\n",
    "audio, sfreq = lr.load('../data/murmur__201101051104.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b639d-19c9-4e07-83bc-3be351658855",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f2cda-4d23-4fd5-91bf-d21e6e5235a9",
   "metadata": {},
   "source": [
    "Knowing the sampling rate of a timeseries we can know the timestamp of each datapoint relative to the first datapoint.\n",
    "\n",
    "(assuming the sampling rate is fixed and no datapoints are lost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c203a6b-551f-4415-bab4-4d57183b43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28874c-cc28-4af2-91a4-79f091ea6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c3a037-b660-4d5c-837f-7f2e69f0b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(0, len(audio))\n",
    "time = indices/sfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400db5bd-5df7-4907-b69e-6dd7b3eed374",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ebe4d-cd7c-47c0-a3b8-19b64b909c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv('../data/prices.csv', parse_dates=['date'], index_col='date')\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879eb9e-de30-4fe0-8527-06b72fbb0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_prices = prices.pivot(values='close', columns='symbol')\n",
    "pivot_prices = pivot_prices[['AAPL', 'FB', 'NFLX', 'V']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d57c3-d2e9-4ab6-968a-9032e824bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each column, plot its values over time\n",
    "fig, ax = plt.subplots()\n",
    "for column in pivot_prices.columns:\n",
    "    pivot_prices[column].plot(ax=ax, label=column)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea86e0c-2577-47b8-94d4-fd63e87433d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob(\"../data/heartbeat/set_a/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bae497-31f5-41df-9a32-8cdd130cbd1d",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "A first version can be to try to predict each class based on the max, std and mean of each signal.\n",
    "\n",
    "## improving the features used for classification\n",
    "\n",
    "### AudioEnvelope\n",
    "\n",
    "Smooth the data to calculate the auditory envelope\n",
    "\n",
    "Related to the total amount of audio energy present at each moment of time (rectifying the signal, that is, taking the absolute value of each point in time)\n",
    "\n",
    "Performing a local average, smoothing the timeseries (rolling window), removes short term noise while retaining the general pattern\n",
    "\n",
    "### The Tempogram\n",
    "\n",
    "We can summarize more complex temporal information with timeseries specific functions\n",
    "\n",
    "Libros is a great library for auditoyu and imeseries feature engineering\n",
    "\n",
    "The tempogram estimates the tempo of a sound over time\n",
    "\n",
    "We can calculate summary statistics of tempo in the same way that we can for the envelope\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39419f4d-fa23-4038-b547-5033264582e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tempo = lr.beat.tempo(audio, sr=sfreq, hop_length=2**6, aggregate=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70aaa5-f014-4109-a43d-8e33cb46fc0c",
   "metadata": {},
   "source": [
    "### The spectogram \n",
    "\n",
    "Timeseries data can be described as a combination of quickly-changing things and slowly-\n",
    "changing things\n",
    "\n",
    "At each moment in time, we can describe the relative presence of fast- and slow-moving components\n",
    "\n",
    "The simplest way to do this is called a Fourier Transform\n",
    "\n",
    "This converts a single timeseries into an array that describes the timeseries as a\n",
    "combination of oscillations\n",
    "\n",
    "We can calculate the STFT with librosa\n",
    "\n",
    "There are several parameters we can tweak \n",
    "\n",
    "we can visualize the spectogram with the specshow function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987abd2d-3b43-40d5-9e0e-ce8f7225bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions we'll use for the STFT\n",
    "from librosa.core import stft, amplitude_to_db from librosa.display import specshow import matplotlib. pyplot as plt\n",
    "\n",
    "# Calculate our STFT\n",
    "HOP_LENGTH = 2**4\n",
    "SIZE_WINDOW = 2**7\n",
    "audio_spec = stft(audio, hop_Length=HOP_LENGTH, n_fft=SIZE_WINDOW)\n",
    "\n",
    "# Convert into decibels for visualization\n",
    "spec_db = amplitude_to_db(audio_spec)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots)\n",
    "specshow(spec_db, sp=sfrea, x_axis='time',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20208c-46fd-4f0f-9f6f-12fbff419039",
   "metadata": {},
   "source": [
    "## Dealing with Real World Data\n",
    "\n",
    "When dealing with real data we can face gaps in the time series.\n",
    "\n",
    "One usual solution for this is to **interpolate** in the gaps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4433d5e1-9f50-4ba9-ac17-363e8149851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_prices.loc['2012':'2013', 'AAPL']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca1602-53b2-41ae-8e74-87fcc3662828",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_prices.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90564d-0ff1-42ad-95e8-8bebd9dc63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_prices.interpolate('linear').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f415d-9d7c-4b71-a471-e4b23e6f5d2f",
   "metadata": {},
   "source": [
    "We can use rolling windows to transform the data by smoothing it.\n",
    "\n",
    "Rolling windows can be used to do more complex transformations.\n",
    "\n",
    "To standardize the variance of a time series we can calculate the % change over a previous window\n",
    "\n",
    "This makes timepoints more comparable to one another if the absolute values of data change a lot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60edd37a-bbba-468a-a42c-3db633fd8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_change(values) :\n",
    "    \"\"\"Calculates the % change between the last value and the mean of previous values\"\"\"\n",
    "    # Separate the last value and all previous values into variables\n",
    "    previous_values = values[:-1]\n",
    "    last_value = values[-1]\n",
    "    # Calculate the % difference between the last value\n",
    "    # and the mean of earlier values\n",
    "    \n",
    "    percent_change = (last_value - np.mean (previous_values)) \\\n",
    "        / np. mean (previous_values)\n",
    "    return percent_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0a03e-db1a-4e19-819d-4d0d42d29d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_prices.NFLX.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d232fd1-40aa-4f95-832f-2eb3d3536f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10, 5))\n",
    "ax = pivot_prices.NFLX.plot(ax = axs[0])\n",
    "\n",
    "ax = pivot_prices.NFLX.rolling(window=20).aggregate(percent_change).plot(ax = axs[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe44d0-67ca-46b7-a474-375db571e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "This transformation can be used to identify outliers.\n",
    "\n",
    "An outlier is a value that is 3 std away from the mean.\n",
    "\n",
    "We can replace the outliers by the median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a17b6-8500-4fca-8c9b-649d2b423a05",
   "metadata": {},
   "source": [
    "# Creating Features from the past. \n",
    "\n",
    "> A common question to ask when dealing with timeseries is: how smooth is the data? That is how correlated is a timepoint with its neighboring timepoints (autocorrelation). The amount of autocorrelation will impact your models\n",
    "\n",
    "When using cross validation its important to avoid shuffling the data because that would break its temporal structure.\n",
    "\n",
    "SKlearn has the timeSeriesSplit that prevents this issue, ensuring we always use past data to predict the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a7501-8e2d-4a2f-a84c-86aba8109b5b",
   "metadata": {},
   "source": [
    "# Stationarity\n",
    "\n",
    "Stationary time series do not change their statistical properties over time (mean, std..)\n",
    "\n",
    "The stationarity of our data has an impact on the models: non stationary data results in variability in our model.\n",
    "\n",
    "The statistical properties the model find may change with the data. How can we quantify this? \n",
    "\n",
    "One approach is to use cross validation and assess parameter stability across all cv splits.\n",
    "\n",
    "Bootstrapping the mean is another way to assess the stationarity of a timeseries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
