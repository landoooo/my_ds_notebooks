{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f52cfc-f275-47e8-b7ca-2f0721532f42",
   "metadata": {},
   "source": [
    "# Machine Learning with Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170eda79-cf11-43a1-8d8e-7b29381fcd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c3f1e-42ef-49af-a4d0-c02bbaca1f05",
   "metadata": {},
   "source": [
    "Supervised learning is a type of machine learning where the values to be predicted are already known, and a model is built with the aim of accurately predicting values of previously unseen data.\n",
    "\n",
    "2 kinds of supervised learning:\n",
    "- Classification: target variable consists of categories\n",
    "- Regression: target variable is continuous\n",
    "\n",
    "Feature = predictor variable = independent variable\n",
    "Target variable = dependent variable = response variable\n",
    "\n",
    "Before using supervised learning:\n",
    "- no missing values\n",
    "- numeric format\n",
    "- data stored in pandas dataframe or numpy arrays\n",
    "\n",
    "EDA to be performed before doing supervised learning\n",
    "\n",
    "> Scikit-learn follows the same syntax for all the models\n",
    "\n",
    "```\n",
    "from sklearn.module import Model\n",
    "\n",
    "model = Model()\n",
    "model.fit(X,y)\n",
    "predictions = model.predict(X_new)\n",
    "print(predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7bada-d716-4d7a-ad57-9d53fd2f8cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T17:19:39.846102Z",
     "iopub.status.busy": "2024-08-05T17:19:39.845548Z",
     "iopub.status.idle": "2024-08-05T17:19:39.854845Z",
     "shell.execute_reply": "2024-08-05T17:19:39.852359Z",
     "shell.execute_reply.started": "2024-08-05T17:19:39.846061Z"
    }
   },
   "source": [
    "# Classification\n",
    "\n",
    "1. Build a model\n",
    "2. Model learns from the labeled data\n",
    "3. Pass unlabel data to the model as input\n",
    "4. Model predicts the labels of unseen data\n",
    "\n",
    "## k-Nearest Neighbors (KNN)\n",
    "\n",
    "Predicts the label of a data point by\n",
    "- Looking at the k closest labeled data points\n",
    "- Taking a majority vote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8732f2f2-4af0-4209-8ac3-d0fbc18bf11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = pd.read_csv('../data/telecom_churn_clean.csv')\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800cf20-296c-42ae-a55d-9b2dd00368fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=churn, x='account_length', y='customer_service_calls', hue='churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c848cc8-d342-4ad2-aba4-05cd1e194ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# the .values converts the dataFrames into numpy arrays\n",
    "X = churn[['account_length', 'customer_service_calls']].values\n",
    "y = churn.churn.values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f103fbe-1fa0-402c-9185-53f462a87580",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5cfda-52e4-49d1-88e2-3e980ce13fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=np.array([[1, 1],\n",
    "                [0, 0], \n",
    "               [-1, -1]])\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f59daa-fe69-46aa-ba62-1364d8b290eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knn.predict(X_new)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad771a2-01f7-459e-bf50-3ea4fbe08a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T17:49:55.296309Z",
     "iopub.status.busy": "2024-08-05T17:49:55.294719Z",
     "iopub.status.idle": "2024-08-05T17:49:55.312518Z",
     "shell.execute_reply": "2024-08-05T17:49:55.311376Z",
     "shell.execute_reply.started": "2024-08-05T17:49:55.296235Z"
    }
   },
   "source": [
    "The `n_neighbors` parameter in a K-Nearest Neighbors (KNN) model specifies the number of closest data points (neighbors) the model considers when making a prediction. Here’s how it impacts the model:\n",
    "\n",
    "1. **Small `n_neighbors` (e.g., 1 or 2):** The model becomes highly sensitive to noise in the data, as predictions are based on very few neighbors. This can lead to overfitting.\n",
    "\n",
    "2. **Large `n_neighbors` (e.g., 10 or more):** The model becomes more robust to noise by averaging over more neighbors, but it may also oversmooth the data, potentially missing patterns and leading to underfitting.\n",
    "\n",
    "In summary, `n_neighbors` controls the trade-off between bias and variance: a small value can capture more complex patterns but may be too sensitive to noise, while a large value smooths out noise but may miss finer details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dccbff-8e53-44ed-899e-eca731c8aed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T17:32:32.461747Z",
     "iopub.status.busy": "2024-08-05T17:32:32.460630Z",
     "iopub.status.idle": "2024-08-05T17:32:32.473290Z",
     "shell.execute_reply": "2024-08-05T17:32:32.471949Z",
     "shell.execute_reply.started": "2024-08-05T17:32:32.461703Z"
    }
   },
   "source": [
    "## Measuring model performance\n",
    "\n",
    "Accuracy is a commonly used metric\n",
    "\n",
    "$$\n",
    "    accuracy = {correct\\_predictions \\over total\\_observations}\n",
    "$$\n",
    "\n",
    "Split data into training and test set. Evaluation has to be performed on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf17c7-03fe-4735-b98c-0050d2ebbee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05533e-b713-4741-a41b-98581b3290cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f867f-0930-461b-a765-e3d972ee7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b432b-2d21-47f3-9a90-77e09d8bb0e6",
   "metadata": {},
   "source": [
    "Lets try different n values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507cc231-8844-4018-a81f-0fedeea1bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = {}\n",
    "test_accuracies = {}\n",
    "neighbors =  np.arange(1, 26)\n",
    "\n",
    "for n in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_accuracies[n] = knn.score(X_train, y_train)\n",
    "    test_accuracies[n] = knn.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8bcb4-4bf0-400d-8533-0611dc0f3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a title\n",
    "plt.title(\"KNN: Varying Number of Neighbors\")\n",
    "\n",
    "# Plot training accuracies\n",
    "plt.plot(neighbors,train_accuracies.values(), label=\"Training Accuracy\")\n",
    "\n",
    "# Plot test accuracies\n",
    "plt.plot(neighbors,test_accuracies.values(),  label=\"Test Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e4855-b8d8-4ec1-a1de-e5a7ca9a3b4b",
   "metadata": {},
   "source": [
    "# Introduction to Regression\n",
    "\n",
    "In these kinds of problems the response variable is typically continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbea08-c52c-4067-a2d9-8d5fe54c3b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv('../data/diabetes_clean.csv')\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90539aa7-5d9c-475d-9407-7c66affec788",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.drop(\"glucose\", axis=1).values\n",
    "y = diabetes_df.glucose.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9413d83-e7e7-46f4-958f-8f03b21a01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bmi = X[:, 3]\n",
    "print(y.shape, X_bmi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e3b30-01cc-43e2-8f72-faff1a535958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the predictor must be a 2 dimensional array to be accepted by sklearn... \n",
    "\n",
    "X_bmi = X_bmi.reshape(-1,1)\n",
    "print(y.shape, X_bmi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1c074-fe36-4e58-81bd-880a94b9e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_bmi, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3025e-537e-480b-bb74-163819614e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_bmi, y)\n",
    "predictions = reg.predict(X_bmi)\n",
    "\n",
    "plt.scatter(X_bmi, predictions)\n",
    "plt.ylabel('Blood glucose')\n",
    "plt.xlabel('Body mass index')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba38c55-5235-4176-a496-0d2a946af10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.drop('glucose', axis=1).values\n",
    "y = diabetes_df.glucose.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2f81e-e7e6-494c-9854-41a86bbfa6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39433a-bb41-42f8-95cb-22af9c61b5e0",
   "metadata": {},
   "source": [
    "The default metric for linear regression is $R^2$ which quantifies the variance in target values explained by the features\n",
    "\n",
    "How to calculate $R^2$ in scikit-learn?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e04e6-8b40-43e2-b555-6912416492e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919bc8e8-96db-423b-b994-73660f28f308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T12:05:22.161794Z",
     "iopub.status.busy": "2024-08-06T12:05:22.161261Z",
     "iopub.status.idle": "2024-08-06T12:05:22.171879Z",
     "shell.execute_reply": "2024-08-06T12:05:22.170711Z",
     "shell.execute_reply.started": "2024-08-06T12:05:22.161760Z"
    }
   },
   "source": [
    "Another helpful measure is the MSE (Mean Squared Error)\n",
    "\n",
    "$$\n",
    " \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 \n",
    "$$\n",
    "where:\n",
    "- $n$ is the number of data points,\n",
    "- $y_i$ is the actual value,\n",
    "- $\\hat{y}_i$ is the predicted value.\n",
    "\n",
    "The MSE is measured in target units, squared.\n",
    "\n",
    "The RMSE, (root square of the MSE) is in the same units as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b928c6e-a49a-418f-bef3-cf9e2c5cba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, y_pred, squared=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2781054-f34e-4e25-8552-c8cec33e2c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T12:20:14.471045Z",
     "iopub.status.busy": "2024-08-06T12:20:14.470351Z",
     "iopub.status.idle": "2024-08-06T12:20:14.476775Z",
     "shell.execute_reply": "2024-08-06T12:20:14.475529Z",
     "shell.execute_reply.started": "2024-08-06T12:20:14.471005Z"
    }
   },
   "source": [
    "## Cross Validation\n",
    "\n",
    "**Cross-Validation** is a technique used to assess the performance of a machine learning model. The process involves the following steps:\n",
    "\n",
    "1. **Split the Data**: Divide the dataset into `k` subsets (folds).\n",
    "2. **Train and Validate**:\n",
    "    - For each fold:\n",
    "        - Use `k-1` folds to train the model.\n",
    "        - Use the remaining fold to validate the model.\n",
    "3. **Repeat**: Repeat the process `k` times, with each fold used exactly once as the validation data.\n",
    "4. **Average the Results**: Calculate the performance metric (e.g., accuracy, MSE) for each fold and average the results.\n",
    "\n",
    "This method ensures that every data point is used for both training and validation, providing a more reliable estimate of the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0ce91-689c-4e89-a8f0-e536db08f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "cv_results = cross_val_score(reg, X, y, cv=kf)\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a00666-4e94-4dbc-9757-a08788da415e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:05:00.928251Z",
     "iopub.status.busy": "2024-08-06T13:05:00.927458Z",
     "iopub.status.idle": "2024-08-06T13:05:00.941200Z",
     "shell.execute_reply": "2024-08-06T13:05:00.939938Z",
     "shell.execute_reply.started": "2024-08-06T13:05:00.928206Z"
    }
   },
   "source": [
    "These are $R^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b763a23-85e3-4424-8acd-d179038a5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(cv_results), np.std(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584fc171-25c8-4621-8cf6-6139c3b1758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(cv_results, [0.025, 0.975]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2196c-284e-4eba-a05e-2ffe5d39a66a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:14:10.622693Z",
     "iopub.status.busy": "2024-08-06T13:14:10.621115Z",
     "iopub.status.idle": "2024-08-06T13:14:10.629569Z",
     "shell.execute_reply": "2024-08-06T13:14:10.628398Z",
     "shell.execute_reply.started": "2024-08-06T13:14:10.622632Z"
    }
   },
   "source": [
    "## Regularized Regression\n",
    "\n",
    "### Ridge Regression\n",
    "\n",
    "**Ridge Regression** adds regularization to the Ordinary Least Squares (OLS) method to address multicollinearity and overfitting. The main differences are:\n",
    "\n",
    "1. **Regularization Term**:\n",
    "    - Ridge Regression introduces a penalty term to the OLS cost function.\n",
    "    - The modified cost function is: \n",
    "\n",
    "    $$ \\text{Ridge Cost Function} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2 $$\n",
    "\n",
    "    where:\n",
    "    - $y_i$ is the actual value.\n",
    "    - $\\hat{y}_i$ is the predicted value.\n",
    "    - $\\beta_j$ are the model coefficients.\n",
    "    - $\\lambda$ is the regularization parameter controlling the strength of the penalty.\n",
    "\n",
    "2. **Impact of Regularization**:\n",
    "    - The penalty term $\\lambda \\sum_{j=1}^{p} \\beta_j^2$ shrinks the coefficients $\\beta_j$ towards zero, reducing their variance.\n",
    "    - This helps in reducing model complexity and prevents overfitting, especially when the number of predictors $p$ is large or when predictors are highly correlated.\n",
    "\n",
    "3. **Trade-off**:\n",
    "    - The choice of $\\lambda$ determines the trade-off between fitting the training data well (low bias) and keeping the model coefficients small (low variance).\n",
    "    - As $\\lambda$ increases, the bias increases, but variance decreases, leading to a more robust model.\n",
    "\n",
    "In summary, Ridge Regression enhances OLS by adding a regularization term that penalizes large coefficients, thereby improving model generalization and addressing issues of multicollinearity and overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19019029-cbcd-42a9-a7a2-801a195e9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "scores = []\n",
    "\n",
    "for alpha in [0.1, 1.0, 10.0, 100.0, 1000.0]:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_predict = ridge.predict(X_test)\n",
    "    scores.append(ridge.score(X_test, y_test))\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba53eb-85ab-4a11-8c80-8e98ff260f80",
   "metadata": {},
   "source": [
    "### Lasso Regression \n",
    "\n",
    "**Lasso Regression** adds regularization to the Ordinary Least Squares (OLS) method, similar to Ridge Regression, but with a key difference in the penalty term. The main features of Lasso Regression are:\n",
    "\n",
    "1. **Regularization Term**:\n",
    "    - Lasso Regression introduces an $L1$ penalty term to the OLS cost function.\n",
    "    - The modified cost function is: \n",
    "\n",
    "    $$\n",
    "    \\text{Lasso Cost Function} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j|\n",
    "    $$\n",
    "\n",
    "    where:\n",
    "    - $y_i$ is the actual value.\n",
    "    - $\\hat{y}_i$ is the predicted value.\n",
    "    - $\\beta_j$ are the model coefficients.\n",
    "    - $\\lambda$ is the regularization parameter controlling the strength of the penalty.\n",
    "\n",
    "2. **Impact of Regularization**:\n",
    "    - The $L1$ penalty term $\\lambda \\sum_{j=1}^{p} |\\beta_j|$ encourages sparsity in the model coefficients, meaning it can drive some coefficients to exactly zero.\n",
    "    - This results in a simpler model that performs feature selection by excluding irrelevant features.\n",
    "\n",
    "3. **Trade-off**:\n",
    "    - The choice of $\\lambda$ determines the trade-off between fitting the training data well (low bias) and maintaining sparsity in the coefficients (low variance).\n",
    "    - As $\\lambda$ increases, more coefficients are set to zero, leading to a sparser model.\n",
    "\n",
    "4. **Key Difference from Ridge Regression**:\n",
    "    - While Ridge Regression (with its $L2$ penalty) shrinks coefficients towards zero, Lasso Regression (with its $L1$ penalty) can shrink coefficients exactly to zero, effectively performing variable selection.\n",
    "\n",
    "In summary, Lasso Regression enhances OLS by adding an $L1$ regularization term that promotes sparsity in the model coefficients, improving model interpretability and feature selection, while addressing issues of overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9217f9-3b8d-44a6-a88a-ea1ae94ae77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "scores = []\n",
    "\n",
    "for alpha in [0.1, 1.0, 10.0, 20.0, 50.0]:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_predict = lasso.predict(X_test)\n",
    "    scores.append(lasso.score(X_test, y_test))\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c4f83-139c-4e6d-ace7-b61e85dcfa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets perform feature selection \n",
    "\n",
    "X = diabetes_df.drop(\"glucose\", axis=1).values\n",
    "y = diabetes_df.glucose.values\n",
    "\n",
    "names=  diabetes_df.drop('glucose', axis=1).columns\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso_coef = lasso.fit(X, y).coef_\n",
    "\n",
    "plt.bar(names, lasso_coef)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5f986-a6a5-4932-afd4-100589dc1809",
   "metadata": {},
   "source": [
    "## Measuring Model Performance\n",
    "\n",
    "Accuracy is not always the best metric: doesnt perform well in case of imbalance data.\n",
    "\n",
    "Confusion matrix is important to calculate metrics like accuracy, precision, recall..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6c955-0237-4993-8a64-01544ae42b02",
   "metadata": {},
   "source": [
    "# Confusion Matrix and Related Metrics\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. It allows visualization of the performance of an algorithm.\n",
    "\n",
    "The matrix itself is $2 \\times 2$ for binary classification and has the following form:\n",
    "\n",
    "|               | Predicted Positive | Predicted Negative |\n",
    "|---------------|--------------------|--------------------|\n",
    "| Actual Positive | True Positive (TP)  | False Negative (FN) |\n",
    "| Actual Negative | False Positive (FP) | True Negative (TN)  |\n",
    "\n",
    "- **True Positive (TP):** The number of correct predictions that the occurrence is positive.\n",
    "- **True Negative (TN):** The number of correct predictions that the occurrence is negative.\n",
    "- **False Positive (FP):** The number of incorrect predictions that the occurrence is positive.\n",
    "- **False Negative (FN):** The number of incorrect predictions that the occurrence is negative.\n",
    "\n",
    "## Metrics Derived from the Confusion Matrix\n",
    "\n",
    "Several metrics can be calculated from the values in the confusion matrix, providing different perspectives on the performance of the classifier:\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "Accuracy is the proportion of true results (both true positives and true negatives) among the total number of cases examined.\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "### Precision (Positive Predictive Value)\n",
    "\n",
    "Precision is the proportion of true positive results in all predicted positive cases.\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "### Recall (Sensitivity or True Positive Rate)\n",
    "\n",
    "Recall is the proportion of true positive results in all actual positive cases.\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "### F1 Score\n",
    "\n",
    "The F1 Score is the harmonic mean of precision and recall, providing a balance between the two metrics.\n",
    "\n",
    "$$\n",
    "\\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "### Specificity (True Negative Rate)\n",
    "\n",
    "Specificity is the proportion of true negative results in all actual negative cases.\n",
    "\n",
    "$$\n",
    "\\text{Specificity} = \\frac{TN}{TN + FP}\n",
    "$$\n",
    "\n",
    "### False Positive Rate (FPR)\n",
    "\n",
    "The False Positive Rate is the proportion of false positive results in all actual negative cases.\n",
    "\n",
    "$$\n",
    "\\text{False Positive Rate} = \\frac{FP}{FP + TN}\n",
    "$$\n",
    "\n",
    "### False Negative Rate (FNR)\n",
    "\n",
    "The False Negative Rate is the proportion of false negative results in all actual positive cases.\n",
    "\n",
    "$$\n",
    "\\text{False Negative Rate} = \\frac{FN}{FN + TP}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146bb7c-c236-4533-bd8d-7a4559c55ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "churn = pd.read_csv('../data/telecom_churn_clean.csv')\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0622e48-4f20-4560-8c94-4e1d074a7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = churn.drop('churn', axis=1).values\n",
    "y = churn.churn.values\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29983aa3-618f-47b3-b8b5-973933eecca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42, stratify=y)\n",
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178be13-1208-4b1c-9871-d5a031e797ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c97f9-0054-406f-aa46-796acfde4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802cbc9-5417-4832-95f3-3c19a503160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa7284-4327-48ba-a40b-d03e9a25d01d",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Used for classification problems\n",
    "\n",
    "Outputs probabilities (values between 0 and 1)\n",
    "\n",
    "If the output p $\\ge$ then the output is labeled as 1. Otherwise, 0\n",
    "\n",
    "Logistic regression provides a linear decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86818c5-50ee-44d8-862d-3345c5587c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42, stratify=y)\n",
    "print(len(X_train), len(y_train))\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(y_pred_probs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec724f-10e7-4dc8-94c0-cd370ae5d60a",
   "metadata": {},
   "source": [
    "By default, the logistic regresion threshold is 0.5\n",
    "\n",
    "We can use the ROC curve to see how different thresholds afect the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64413b69-f846-45de-a833-2e1100df1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "plt.plot([0,1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eed10ae-bd65-4419-88e2-9c2ea956335d",
   "metadata": {},
   "source": [
    "# ROC Curve for Logistic Regression\n",
    "\n",
    "## ROC Curve\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The ROC curve is created by plotting the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.\n",
    "\n",
    "### True Positive Rate (TPR) or Recall\n",
    "\n",
    "The True Positive Rate, also known as Recall or Sensitivity, is the proportion of actual positives that are correctly identified by the classifier.\n",
    "\n",
    "$$\n",
    "\\text{TPR} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "### False Positive Rate (FPR)\n",
    "\n",
    "The False Positive Rate is the proportion of actual negatives that are incorrectly identified as positives by the classifier.\n",
    "\n",
    "$$\n",
    "\\text{FPR} = \\frac{FP}{FP + TN}\n",
    "$$\n",
    "\n",
    "## Interpreting the ROC Curve\n",
    "\n",
    "- **X-axis (False Positive Rate):** Represents the rate of false positives. It ranges from 0 to 1.\n",
    "- **Y-axis (True Positive Rate):** Represents the rate of true positives. It also ranges from 0 to 1.\n",
    "\n",
    "A classifier that randomly guesses has an ROC curve that is a diagonal line from (0, 0) to (1, 1). A good classifier stays as far away from that line as possible, towards the top-left corner.\n",
    "\n",
    "## Area Under the Curve (AUC)\n",
    "\n",
    "The Area Under the ROC Curve (AUC) is a single scalar value that summarizes the performance of the classifier across all thresholds. The AUC can be interpreted as the probability that the classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one.\n",
    "\n",
    "- **AUC = 1.0:** Perfect classifier.\n",
    "- **AUC = 0.5:** Classifier that performs no better than random guessing.\n",
    "- **0.5 < AUC < 1.0:** Classifier performs better than random guessing.\n",
    "\n",
    "## ROC Curve for Logistic Regression\n",
    "\n",
    "Logistic regression outputs probabilities. By varying the decision threshold, different points on the ROC curve can be generated. For example:\n",
    "\n",
    "- **Threshold = 0.5:** The default threshold. Instances with a predicted probability greater than 0.5 are classified as positive.\n",
    "- **Lower Threshold:** More instances are classified as positive, increasing both TPR and FPR.\n",
    "- **Higher Threshold:** Fewer instances are classified as positive, decreasing both TPR and FPR.\n",
    "\n",
    "The ROC curve for logistic regression is generated by calculating the TPR and FPR at different thresholds, and plotting these points.\n",
    "\n",
    "### Example of ROC Curve Points Calculation\n",
    "\n",
    "Let's assume we have the following confusion matrix at different thresholds:\n",
    "\n",
    "1. **Threshold = 0.2:**\n",
    "\n",
    "   - TP = 90\n",
    "   - FP = 30\n",
    "   - TN = 70\n",
    "   - FN = 10\n",
    "\n",
    "   $$\n",
    "   \\text{TPR} = \\frac{90}{90 + 10} = 0.9\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\text{FPR} = \\frac{30}{30 + 70} = 0.3\n",
    "   $$\n",
    "\n",
    "2. **Threshold = 0.5:**\n",
    "\n",
    "   - TP = 70\n",
    "   - FP = 10\n",
    "   - TN = 90\n",
    "   - FN = 30\n",
    "\n",
    "   $$\n",
    "   \\text{TPR} = \\frac{70}{70 + 30} = 0.7\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\text{FPR} = \\frac{10}{10 + 90} = 0.1\n",
    "   $$\n",
    "\n",
    "3. **Threshold = 0.8:**\n",
    "\n",
    "   - TP = 50\n",
    "   - FP = 5\n",
    "   - TN = 95\n",
    "   - FN = 50\n",
    "\n",
    "   $$\n",
    "   \\text{TPR} = \\frac{50}{50 + 50} = 0.5\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\text{FPR} = \\frac{5}{5 + 95} = 0.05\n",
    "   $$\n",
    "\n",
    "By plotting these points $(0.3, 0.9)$, $(0.1, 0.7)$, and $(0.05, 0.5)$ on the ROC curve, and continuing this process for other thresholds, the complete ROC curve is obtained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f24435-89a9-4baa-8be0-f76ba0e794b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# lets calculate the AUC\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80913e45-77a1-406f-8316-161491e43912",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "- For ridge/lasso -> alpha\n",
    "- For KNN, n_neighbors\n",
    "\n",
    "Hyperparameters are the parameters we specify before fitting the model\n",
    "\n",
    "The process to choose the best hyperparameters is called **hyperparameter tuning**\n",
    "\n",
    "It is essential to use cross-validation to avoid overfitting to the test set.\n",
    "\n",
    "We can still split the data and perform cross validation on the training set.\n",
    "\n",
    "We withhold the test set for final evaluation\n",
    "\n",
    "### Grid search cross-validation\n",
    "\n",
    "Create a grid with all the different combinations of hyperparameter values and evaluate them all. Choose the combination that performs the best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2ae01-987c-4ccc-af29-7a7330dbcacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "kf = KFold (n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid={\n",
    "    \"alpha\": np.arange(0.0001, 1, 10),\n",
    "    \"solver\": [\"sag\", 'lsqr']\n",
    "}\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "ridge_cv=GridSearchCV(ridge, param_grid, cv=kf)\n",
    "\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "print(ridge_cv.best_params_, ridge_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582adcea-c4bd-4ccb-98f9-5e11616d3c23",
   "metadata": {},
   "source": [
    "Grid search is great, yet the number of fits to be performed grows exponentially.\n",
    "\n",
    "RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc8fb5-36e9-44f8-b217-49fc04a0d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "kf = KFold (n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid={\n",
    "    \"alpha\": np.arange(0.0001, 1, 10),\n",
    "    \"solver\": [\"sag\", 'lsqr']\n",
    "}\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "ridge_cv=RandomizedSearchCV(ridge, param_grid, cv=kf, n_iter=2)\n",
    "\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "print(ridge_cv.best_params_, ridge_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8302a3e-f849-4417-bbbf-28ce06e97771",
   "metadata": {},
   "source": [
    "## Preprocesing Data\n",
    "\n",
    "Scikit learn requires:\n",
    "- Numeric Data\n",
    "- No missing values\n",
    "\n",
    "Real world data is often not like that. Preprocessing the data is required.\n",
    "\n",
    "### Categorical features\n",
    "\n",
    "Not accepted by sklearn. \n",
    "\n",
    "Need to convert them into numeric\n",
    "\n",
    "Often converted to binary features called dummy variables (sklearn OneHotEncoder() and pandas get_dummies())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab118a5-bce6-4ef1-89b9-77b201df141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = pd.read_csv('../data/fish.csv')\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22278c66-9930-4271-8e4d-8a87e4264a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_dummies = pd.get_dummies(fish.species, drop_first=True)\n",
    "fish_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7577f1e-9ef4-4d60-aa15-01213d5486bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_dummies = pd.concat([fish, fish_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f1a1e-5359-4270-aa3c-f950b4ade846",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a9cfa-62c5-47a6-b1e4-d34d3dd8c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_dummies = fish_dummies.drop('species', axis=1)\n",
    "fish_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a463a65-7202-42cc-ae04-3a04a2256caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative version. one single step\n",
    "fish_dummies_2 = pd.get_dummies(fish, drop_first=True)\n",
    "fish_dummies_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04a912-35b7-4511-8612-c53f0d5a80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = fish_dummies.drop('mass_g', axis = 1).values\n",
    "y = fish.mass_g.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg_cv = cross_val_score(linreg, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "#sklearn cv considers a higher score is better, thats why we use the neg_mean_squared_error\n",
    "\n",
    "print(np.sqrt(-linreg_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fbec02-fb1d-43c7-9e30-8cad4b4e01fe",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "Reasons to have missing data are multiple: no observation, data corruption...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f5c89-2029-41e6-9282-52fbcca21b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.read_csv('../data/music.csv')\n",
    "music_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1139137-f2bf-4274-a33b-9e097c30d542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T11:57:43.512078Z",
     "iopub.status.busy": "2024-08-09T11:57:43.511286Z",
     "iopub.status.idle": "2024-08-09T11:57:43.520869Z",
     "shell.execute_reply": "2024-08-09T11:57:43.519502Z",
     "shell.execute_reply.started": "2024-08-09T11:57:43.512032Z"
    }
   },
   "source": [
    "#### Dropping Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596d750-4163-4b8c-b4b4-c06f80e97d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "music_df = music_df.dropna(subset=['genre', 'popularity', 'loudness', 'liveness', 'tempo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d544f0-345b-4b0e-8bed-2be8fd949d23",
   "metadata": {},
   "source": [
    "If there is any missing value in any of the features of the subset, the whole row is removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa2c39-eb41-4686-8d04-489b0fc79a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(music_df.isna().sum().sort_values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dbbe9-7244-4edb-a3db-15eb57c04e99",
   "metadata": {},
   "source": [
    "### Imputation \n",
    "\n",
    "Use subject-matter expertise to replace missing data with educated guesses\n",
    "\n",
    "Common to use mean\n",
    "\n",
    "Can also use the median or another value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c9370-9ab3-47a9-93ec-8f4330b4a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_cat = music_df['genre'].values.reshape(-1, 1)\n",
    "X_num = music_df.drop(['genre', 'popularity'], axis = 1).values\n",
    "y = music_df['popularity'].values\n",
    "\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(X_cat, y, test_size=0.2, random_state=42)\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=42)\n",
    "\n",
    "imp_cat = SimpleImputer(strategy='most_frequent')\n",
    "X_train_cat = imp_cat.fit_transform(X_train_cat)\n",
    "X_test_cat = imp_cat.transform(X_test_cat)\n",
    "\n",
    "imp_num = SimpleImputer()\n",
    "X_train_num = imp_num.fit_transform(X_train_num)\n",
    "X_test_num = imp_num.transform(X_test_num)\n",
    "\n",
    "X_train = np.append(X_train_num, X_train_cat, axis=1)\n",
    "\n",
    "X_test = np.append(X_test_num, X_test_cat, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab20acd1-d6d4-40e5-ace3-9ea61c7374cc",
   "metadata": {},
   "source": [
    "Imputers are known as transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd64407-b8b1-4cd3-9a85-383301059d69",
   "metadata": {},
   "source": [
    "### Imputing within a pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb855320-1acf-4cf5-acaa-4777b639437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "music_df = music_df.dropna(subset=['genre', 'popularity', 'loudness', 'liveness', 'tempo'])\n",
    "\n",
    "music_df['genre'] = np.where(music_df.genre == 'Rock', 1, 0) \n",
    "\n",
    "X = music_df.drop('genre', axis=1).values\n",
    "y = music_df.genre.values\n",
    "\n",
    "steps=[(\"imputation\", SimpleImputer()), \n",
    "      \"logistic_regression\", LogisticRegression()]\n",
    "\n",
    "pipeline = Pipeline(steps) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1c6a8e-5cc2-4bff-94c7-91a70977f803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T13:34:49.823275Z",
     "iopub.status.busy": "2024-08-09T13:34:49.822112Z",
     "iopub.status.idle": "2024-08-09T13:34:49.831185Z",
     "shell.execute_reply": "2024-08-09T13:34:49.829848Z",
     "shell.execute_reply.started": "2024-08-09T13:34:49.823198Z"
    }
   },
   "source": [
    "### Centering and Scaling data\n",
    "\n",
    "Many models use some form of distance to inform them\n",
    "\n",
    "Features on larger scales can disproportionately influence the model\n",
    "\n",
    "For this reason we want features to be on a similar scale -> Normalization or Standardization (scaling and centering)\n",
    "\n",
    "- **Standardization**: subtract the mean and divide by variance -> all features are centered around zero and have a variance of one.\n",
    "- Subtract the minimum and divide by the range.\n",
    "- **Normalization**: so the data ranges from -1 to +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c2c81-09a5-45b8-a1f9-cef1dc439cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "music_df = pd.read_csv('../data/music.csv')\n",
    "\n",
    "music_df = music_df.dropna()\n",
    "\n",
    "X = music_df.drop(\"genre\", axis=1).values\n",
    "y = music_df.genre.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(np.mean(X), np.std(X))\n",
    "print(np.mean(X_train_scaled), np.std(X_train_scaled))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e0c21-8d59-41df-8950-f6a360d1530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30082bf-5a04-4f5c-8f22-41044765338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "        ('knn', KNeighborsClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'knn__n_neighbors': np.arange(1,50)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "print(cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69d1200-1bf2-4700-bd7e-b530b9f0d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a175a23-12b2-497c-9d61-33fed216f260",
   "metadata": {},
   "source": [
    "# Evaluating Multiple Models \n",
    "\n",
    "there are different models for different problems.\n",
    "\n",
    "Some guiding principles:\n",
    "- Size of the dataset\n",
    "- Interpretability\n",
    "- Fleibility\n",
    "\n",
    "Metrics are key to compare the performance of different models.\n",
    "\n",
    "- For regression problems, RMSE or $R^2$\n",
    "- For classification models, Accuracy, Confussion Matrix, precision, recall, F1 Score, ROC AUC\n",
    "\n",
    "Some models are affected by the scale of the features: knn, linear regression, logistic regression, artificial neural networks, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d582ad-772a-403d-a01f-39bf74013a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "music_df = pd.read_csv('../data/music.csv')\n",
    "\n",
    "music_df = music_df.dropna()\n",
    "\n",
    "X = music_df.drop(\"genre\", axis=1).values\n",
    "y = music_df.genre.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models={\n",
    "    \"Log Reg\": LogisticRegression(), \n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "}\n",
    "\n",
    "results=[]\n",
    "\n",
    "for model in models.values():\n",
    "    kf= KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "    cv_results=cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "    results.append(cv_results)\n",
    "\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cbdda7-a1ac-4f3d-b258-c9aea8ae4c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    test_score = model.score(X_test_scaled, y_test)\n",
    "    print(\"{} Test Set Accuracy: {}\".format(name, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b588d-3dbc-4ff2-a978-2583e5f1cf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
