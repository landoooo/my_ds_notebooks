{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e76f62e-5c07-4a3f-a648-b9b480ae4d51",
   "metadata": {},
   "source": [
    "# Creating a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55193d14-68b8-4bfe-8976-54a2659f8368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from torch.utils.data import Dataset \n",
    "\n",
    "class WaterDataset(Dataset): \n",
    "    def __init__(self, csv_path): \n",
    "        df=pd.read_csv(csv_path)\n",
    "        self.data = df.to_numpy() \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] \n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        features = self.data[idx, :-1]\n",
    "        label = self.data[idx, -1]\n",
    "        return features, label \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03177a19-2b36-4a44-8a54-2b94ee716dc2",
   "metadata": {},
   "source": [
    "# Creating a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278d592-65b2-43ad-baad-a7a14380bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = WaterDataset(\"../data/water_potability.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5219a35-4dbb-433d-90af-30b624cd1986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train, \n",
    "    batch_size=2, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "features, labels = next(iter(dataloader_train))\n",
    "print(f\"features: {features}, \\nLabels: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a305069-e308-411f-aaaa-bc4f459814b6",
   "metadata": {},
   "source": [
    "# Defining a Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef32eb-7742-4465-81c4-179952de636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(Net, self).__init__() \n",
    "        self.fc1 = nn.Linear(9,16)\n",
    "        self.fc2 = nn.Linear(16,8)\n",
    "        self.fc3 = nn.Linear(8,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.sigmoid(self.fc3(x))\n",
    "        return x \n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f558ce39-deaf-483c-aefd-4f880fb3c701",
   "metadata": {},
   "source": [
    "# Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531c1bc-4de1-40d9-a340-2a9fc36d4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000): \n",
    "    for features, labels in dataloader_train: \n",
    "        features = features.float() \n",
    "        optimizer.zero_grad() \n",
    "        outputs = net(features)\n",
    "        loss = criterion(\n",
    "            outputs.double(), labels.view(-1, 1)\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e59252-c7e4-416b-b83c-1e5b7fbd4874",
   "metadata": {},
   "source": [
    "# Optimizing Weights \n",
    "\n",
    "The most used optimazer is **Adam** (Adaptative Momentum) that mixes RMSProp and gradient momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914df78-dbae-415d-b2e3-6f6a6abcb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad90de-3591-457f-b4ef-a0df542df058",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c9fae-39ae-4960-a488-4c7e20e59dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since I dont know yet how to do the train test split in pytorch.... \n",
    "dataloader_test = dataloader_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536350d7-e8ec-45ea-a343-4af1aac80f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy \n",
    "\n",
    "acc = Accuracy(task='binary') \n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for features, labels in dataloader_test: \n",
    "        outputs = net(features.float()) \n",
    "        preds = (outputs >=0.5).float()\n",
    "        acc(preds, labels.view(-1, 1))\n",
    "\n",
    "accuracy = acc.compute() \n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a9f51-6872-41d8-8c57-82e8b42f864c",
   "metadata": {},
   "source": [
    "# Unstable Gradients\n",
    "Neural networks often suffer from gradient instability during training. Sometimes, the gradients become smaller during the backward pass, known as **vanishing gradients**. As a result, earlier layers receive minimal parameter updates, hindering the model's ability to learn. In contrast, gradients may grow increasingly large, leading to massive parameter updates and divergent training, known as **exploding gradients**.\n",
    "\n",
    "To address these issues, a three-step approach is recommended: proper weights initialization, appropriate activation functions, and batch normalization.\n",
    "\n",
    "## Weights Initialization\n",
    "When a torch layer is created, its parameters in the weight attribute are initialized to random values. Research suggests initialization should maintain the variance of inputs and outputs and ensure the variance of gradients is consistent before and after passing through the layer. For ReLU and similar activations, He initialization (also known as Kaiming initialization) is typically used.\n",
    "\n",
    "### He / Kaiming Initialization\n",
    "To apply this initialization, call `kaiming_uniform_` from `torch.nn.init` on the layer's weight attribute, ensuring the desired variance properties. In the final layer using sigmoid activation, specify the nonlinearity as sigmoid during initialization.\n",
    "\n",
    "## Activation Functions\n",
    "The ReLU (Rectified Linear Unit) is the most commonly used activation function. While efficient, it suffers from the dying neuron problem: neurons output zero for any negative input, effectively dying. The ELU (Exponential Linear Unit) activation improves upon ReLU by allowing non-zero gradients for negative values, reducing the likelihood of vanishing gradients and dying neurons.\n",
    "\n",
    "## Batch Normalization\n",
    "Even with proper weights and activations, unstable gradients can still arise during training. Batch normalization addresses this by normalizing a layer's outputs, ensuring the output distribution is roughly normal. It then applies learned scale and shift parameters, allowing the model to learn optimal input distributions for each layer. This stabilizes gradient behavior and accelerates loss convergence.\n",
    "\n",
    "To implement batch normalization in PyTorch, define the `BatchNorm1d` layer in the model's `__init__` method, matching the preceding layer's output size. Then, pass the linear layer's output to the batch normalization layer before applying the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed1438-7f5a-41b2-8e1a-74631fc6c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        \n",
    "        # Apply He initialization\n",
    "        init.kaiming_uniform_(self.fc1.weight)\n",
    "        init.kaiming_uniform_(self.fc2.weight)\n",
    "        init.kaiming_uniform_(\n",
    "            self.fc3.weight, \n",
    "            nonlinearity='sigmoid'\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Update ReLU activation to ELU\n",
    "        x = nn.functional.elu(self.fc1(x))\n",
    "        x = nn.functional.elu(self.fc2(x))\n",
    "        x = nn.functional.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd596880-105c-4b41-9f89-17c3d40ced56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T15:09:23.806682Z",
     "iopub.status.busy": "2024-09-24T15:09:23.805725Z",
     "iopub.status.idle": "2024-09-24T15:09:23.817445Z",
     "shell.execute_reply": "2024-09-24T15:09:23.815953Z",
     "shell.execute_reply.started": "2024-09-24T15:09:23.806637Z"
    }
   },
   "source": [
    "# Handling Images in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc49ec-b1c8-4212-9268-019eabfd5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder \n",
    "from torchvision import transforms \n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Resize((128, 128))\n",
    "])\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "    \"../data/clouds/clouds_train\",\n",
    "    transform = train_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf49080-487b-4a82-995c-594c8bcb42e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    dataset_train, \n",
    "    shuffle = True,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "image, label = next(iter(dataloader_train))\n",
    "print(image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f22585-be1a-4403-8745-8c283fd4c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image= image.squeeze().permute(1, 2, 0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b07e3-963c-4700-a9d9-22f1e677e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781135a4-686f-4f89-be03-a35e60e6f819",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "> When doing data augmentation always keep the data and the task in mind, since sometimes the augmented data could correspond to other classes!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae87341-b304-4c7b-9b58-0b4f7b924cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Resize((128, 128))\n",
    "])\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "    \"../data/clouds/clouds_train\",\n",
    "    transform = train_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34493976-128b-46e1-ab0c-ddb5b4c123dc",
   "metadata": {},
   "source": [
    "# Convolutional neural networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175d0ae-f9c0-4037-953c-8ce03e0fd273",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): \n",
    "    def __init__(self, num_classes): \n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), \n",
    "            nn.ELU(), \n",
    "            nn.MaxPool2d(kernel_size=2), \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), \n",
    "            nn.ELU(), \n",
    "            nn.MaxPool2d(kernel_size=2), \n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd73e10-6f29-48fa-8d0e-c59b65c04ae8",
   "metadata": {},
   "source": [
    "# Training convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6805a56-a9eb-4a3a-8c81-79fe86e81845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multiclass classification we use CrossEntropyLoss\n",
    "\n",
    "net = Net(num_classes=7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    # Iterate over training batches\n",
    "    for images, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader_train)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c71363-c4f5-42db-9fa7-857564a85fe8",
   "metadata": {},
   "source": [
    "# Evaluate image classifiers \n",
    "\n",
    "In multiclass classification we separate precision and recall for each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62913f-4dd2-4edb-a438-d737e10907a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Recall \n",
    "\n",
    "recall_per_class = Recall(task='multiclass', num_classes=7, average=None)\n",
    "recall_micro = Recall(task='multiclass', num_classes=7, average=\"micro\")\n",
    "recall_macro = Recall(task='multiclass', num_classes=7, average=\"macro\")\n",
    "recall_weighted = Recall(task='multiclass', num_classes=7, average=\"weighted\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3475ede1-aa29-41ce-8b5e-7999bf727ece",
   "metadata": {},
   "source": [
    "# Multi-Class Classification Metrics and Averaging Methods\n",
    "\n",
    "In multi-class classification, where we have more than two classes, calculating evaluation metrics such as **precision**, **recall**, and **F1-score** becomes more complex than in binary classification. Various averaging methods are used to combine per-class metrics into a single overall score. Hereâ€™s an overview of the common averaging techniques:\n",
    "\n",
    "## Micro Averaging\n",
    "- **Definition**: This method aggregates contributions from all classes to compute the average metric globally.\n",
    "- **How it works**: It calculates the total true positives (TP), false positives (FP), and false negatives (FN) across all classes and then computes the metrics.\n",
    "- **Best suited for**: Cases where each class's importance is the same, especially when dealing with imbalanced datasets.\n",
    "  \n",
    "  **Formula**:  \n",
    "  $\\text{Precision}_\\text{micro} = \\frac{\\sum_{i} TP_i}{\\sum_{i} (TP_i + FP_i)}$  \n",
    "\n",
    "  $\\text{Recall}_\\text{micro} = \\frac{\\sum_{i} TP_i}{\\sum_{i} (TP_i + FN_i)}$  \n",
    "\n",
    "  $\\text{F1}_\\text{micro} = 2 \\cdot \\frac{\\text{Precision}_\\text{micro} \\cdot \\text{Recall}_\\text{micro}}{\\text{Precision}_\\text{micro} + \\text{Recall}_\\text{micro}}$\n",
    "\n",
    "## Macro Averaging\n",
    "- **Definition**: This method computes the metric independently for each class and then takes the average (unweighted mean).\n",
    "- **How it works**: Each class is treated equally, regardless of its size.\n",
    "- **Best suited for**: When all classes are equally important, even if they have very different sample sizes.\n",
    "  \n",
    "  **Formula**:  \n",
    "  $\\text{Precision}_\\text{macro} = \\frac{1}{N} \\sum_{i} \\text{Precision}_i$  \n",
    "\n",
    "  $\\text{Recall}_\\text{macro} = \\frac{1}{N} \\sum_{i} \\text{Recall}_i$  \n",
    "\n",
    "  $\\text{F1}_\\text{macro} = \\frac{1}{N} \\sum_{i} \\text{F1}_i$\n",
    "  \n",
    "  where $N$ is the number of classes.\n",
    "\n",
    "## Weighted Averaging\n",
    "- **Definition**: This method computes the metric for each class independently, but the average is weighted by the number of instances of each class.\n",
    "- **How it works**: Classes with more samples have a larger impact on the overall score.\n",
    "- **Best suited for**: Imbalanced datasets, where the model should perform better on larger classes.\n",
    "\n",
    "  **Formula**:  \n",
    "  $\\text{Precision}_\\text{weighted} = \\sum_{i} \\frac{n_i}{n} \\cdot \\text{Precision}_i$  \n",
    "\n",
    "  $\\text{Recall}_\\text{weighted} = \\sum_{i} \\frac{n_i}{n} \\cdot \\text{Recall}_i$  \n",
    "\n",
    "  $\\text{F1}_\\text{weighted} = \\sum_{i} \\frac{n_i}{n} \\cdot \\text{F1}_i$\n",
    "  \n",
    "  where $n_i$ is the number of samples in class $i$, and $n$ is the total number of samples across all classes.\n",
    "\n",
    "## Per-Class Metrics (No Averaging)\n",
    "- **Definition**: In some cases, you may want to evaluate each class independently, without averaging metrics across classes. This can be useful in highly imbalanced datasets or when certain classes are more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572c578-b2fd-455b-aaf9-e5dc14a21395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Precision, Recall \n",
    "\n",
    "metric_precision = Precision(\n",
    "    task=\"multiclass\", num_classes=7, average=\"macro\"\n",
    ")\n",
    "metric_recall = Recall(\n",
    "    task=\"multiclass\", num_classes=7, average=\"macro\"\n",
    ")\n",
    "\n",
    "net.eval() \n",
    "with torch.no_grad(): \n",
    "    for images, labels in dataloader_test: \n",
    "        outputs = net(images.float())\n",
    "        _, preds = torch.max(outputs,1)\n",
    "        metric_precision(pred, labels)\n",
    "        metric_recall(preds, labels)\n",
    "\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b8699-f470-48b0-b6b8-83ee79b54b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix these last cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49ef71-c19a-4431-9d14-33dc40c6df89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
