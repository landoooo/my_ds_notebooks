{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b261949f-b6a3-4c0c-b6f7-1e8403f2b659",
   "metadata": {},
   "source": [
    "<center><img src=\"educational_quiz_bot.jpg\" width=300></center>\n",
    "\n",
    "    \n",
    "Quizzes are a useful way to practice what you or your students have learned and to keep track of progress. In this project, you'll build a educational quiz bot to help you generate quiz questions. Imagine you are a teacher needing to create a pop quiz based on your most recent lecture, or you are a student wanting to quiz yourself on this lecture. This tool will help you automate this task, track which questions have been asked to avoid repetition, and validate the responses.\n",
    "\n",
    "You'll leverage OpenAI and prompt engineering to generate relevant questions.\n",
    "\n",
    "### The Data:\n",
    "\n",
    "This quiz bot allows you to generate quizzes from any educational text. You have been provided with a sample data file from a physics-focused corpus, stored in the `physics_lecture.txt` file.\n",
    "\n",
    "The text covers fundamental physics concepts, including speed, velocity, Newton's third law, and more. This content is sourced from ScienceQA (Saikh et al., 2022), a dataset originally designed for Machine Reading Comprehension (MRC) tasks. For this project, the dataset has been filtered to focus specifically on natural science topics related to physics, making it ideal for use with the quiz bot.\n",
    "\n",
    "Source: `https://huggingface.co/datasets/tasksource/ScienceQA_text_only?row=40`\n",
    "Saikh, Tanik et al. “ScienceQA: a novel resource for question answering on scholarly articles.” International Journal on Digital Libraries 23 (2022): 289 - 301.\n",
    "\n",
    "Image generated with DALL-E (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa14cf8e-a933-4a6b-9fed-90b1fd10f152",
   "metadata": {
    "collapsed": false,
    "executionCancelledAt": null,
    "executionTime": 2493,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "lastExecutedAt": 1733917863286,
    "lastExecutedByKernel": "cc2102cf-09f2-4798-911a-5fa6bd415852",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import OpenAI and supporting libraries\nimport os\nfrom openai import OpenAI\n\ndef read_text_from_file(filename):\n    \"\"\"\n    Reads the first 500 lines of content from a file and returns it as a string.\n    Args: filename (str): The name of the file to read.\n    Returns: str: The content of the file as a string, or an empty string if the file is not found.\n    \"\"\"\n    try:\n        with open(filename, 'r') as file:\n            return ''.join([next(file) for _ in range(500)])\n    except FileNotFoundError:\n        print(f\"Error: {filename} not found.\")\n        return \"\"\n\n# Read content from the file\ncontent = read_text_from_file(\"physics_lecture.txt\")\n\n# Set up the OpenAI client\nclient = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n\n# Setting up the recommended model\nmodel = \"gpt-4o-mini\"",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import OpenAI and supporting libraries\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "def read_text_from_file(filename):\n",
    "    \"\"\"\n",
    "    Reads the first 500 lines of content from a file and returns it as a string.\n",
    "    Args: filename (str): The name of the file to read.\n",
    "    Returns: str: The content of the file as a string, or an empty string if the file is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            return ''.join([next(file) for _ in range(500)])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {filename} not found.\")\n",
    "        return \"\"\n",
    "\n",
    "# Read content from the file\n",
    "content = read_text_from_file(\"physics_lecture.txt\")\n",
    "\n",
    "# Set up the OpenAI client\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Setting up the recommended model\n",
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3192275-df59-4dee-9f42-fd782fc4e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start coding here\n",
    "# Add as many cells as you like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89215f0c",
   "metadata": {},
   "source": [
    "Define the system prompt in a variable system_prompt to specify the chatbot's role as a quiz bot. The prompt should describe its purpose to generate multiple-choice questions from educational text and support educators by creating structured quizzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13b0889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"You are a quiz bot. You are supposed to generate multiple-choice questions from educational text and support educators by creating structured quizzes.\n",
    "Uset the following text to generate questions:\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc9dc7",
   "metadata": {},
   "source": [
    "Create the user prompt template as a variable user_prompt, specifying the format for quiz questions, including sections for \"Question:\", \"Options:\", and \"Answer:\". The template should clearly guide the model in structuring its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce3bfa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"\"\"\n",
    "The format of the quiz questions should be multiple-choice questions with 4 options. Take the example:\n",
    "- \"Question:\" What is the capital of France?\n",
    "- \"Options:\"\n",
    "    - \"A:\" London\n",
    "    - \"B:\" Paris\n",
    "    - \"C:\" Berlin\n",
    "    - \"D:\" Madrid\n",
    "---------\n",
    "\n",
    "-\"Answer:\" B\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc918e",
   "metadata": {},
   "source": [
    "Define and run a function that combines your prompts and generates five quiz questions with the OpenAI API. Store the generated quiz output in a list variable quiz_data, ensuring each entry follows the defined structure, including the format in user_prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "952d0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response\n",
    "\n",
    "messages = [{\"role\": \"system\",\n",
    "             \"content\": system_prompt}, \n",
    "             {\"role\": \"user\", \n",
    "              \"content\": user_prompt}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4521792",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_data = [get_response(messages).choices[0].message.content for i in range(5)]\n",
    "print(quiz_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43577af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "BaseML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
