{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents in Langchain\n",
    "\n",
    "## Agents\n",
    "\n",
    "Autonomous systems that make decisions and take actions. They can solve math problems, perform searches on wikipedia or decide when to switch between LLM and tools for an specific task for instance.\n",
    "\n",
    "Agents can *reason* and *act* (ReAct)\n",
    "\n",
    "## Tools \n",
    "\n",
    "Functions used by agents to perform specific tasks (querying data, research reports, data analysis...)\n",
    "\n",
    "## Graphs\n",
    "\n",
    "LangGraph is another framework from the langchain family that that allows to create graphs (workflows) of agents and tools. In these graphs, tasks (nodes) are connected by edges (rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import math\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(openai_api_key = os.environ[\"OPENAI_API_KEY\"], model='gpt-4o-mini')\n",
    "\n",
    "\n",
    "def count_r_in_word(word: str) -> int:\n",
    "    \"\"\"Counts the number of occurrences of the letter 'r' in a given word.\"\"\"\n",
    "    return word.lower().count(\"r\")\n",
    "\n",
    "agent = create_react_agent(model, tools=[count_r_in_word])\n",
    "\n",
    "query = \"WHow many r's are in the word 'Terrarium'?\"\n",
    "\n",
    "response = agent.invoke({\"messages\": [(\"human\", query)]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building custom functions \n",
    "\n",
    "Although there is already a set of pre-built and custom tools avaiable for database querying, web scrapping, image generation, etc. you can create your own tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool \n",
    "def rectangle_area(input: str) -> int:\n",
    "    \"\"\"Calculates the area of a rectangle given its length and width.\"\"\"\n",
    "    sides = input.split(\",\")\n",
    "    a = float(sides[0].strip())\n",
    "    b = float(sides[1].strip())\n",
    "    return a*b\n",
    "\n",
    "tools=[rectangle_area]\n",
    "\n",
    "query = \"What is the area of a rectangle with sides 10, 20?\"\n",
    "\n",
    "agent = create_react_agent(model, tools=tools)\n",
    "\n",
    "response = agent.invoke({\"messages\": [(\"human\", query)]})\n",
    "print(response['messages'][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "message_history = response[\"messages\"]\n",
    "new_query = \"What about one with sides 12 and 14?\"\n",
    "\n",
    "# Invoke the app with the full message history\n",
    "response = agent.invoke({\"messages\": message_history + [(\"human\", new_query)]})\n",
    "\n",
    "# Extract the human and AI messages from the result\n",
    "filtered_messages = [\n",
    "    msg\n",
    "    for msg in response[\"messages\"]\n",
    "    if isinstance(msg, (HumanMessage, AIMessage)) and msg.content.strip()\n",
    "]\n",
    "\n",
    "# Pass the new query as input and print the final outputs\n",
    "print(\n",
    "    {\n",
    "        \"user_input\": new_query,\n",
    "        \"agent_output\": [\n",
    "            f\"{msg.__class__.__name__}: {msg.content}\" for msg in filtered_messages\n",
    "        ],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs\n",
    "\n",
    "### Graph State\n",
    "\n",
    "Organizes the order of tasks (tool usage and llm calls)\n",
    "\n",
    "### Agent State\n",
    "\n",
    "Tracks the agents progress as text\n",
    "\n",
    "Start and End nodes are prebuilt in langgraph\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated \n",
    "from typing_extensions import TypedDict \n",
    "\n",
    "from langgraph.graph import StateGraph, START, END \n",
    "from langgraph.graph.message import add_messages \n",
    "\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=\"gpt-4o-mini\")\n",
    "\n",
    "class State(TypedDict): \n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "def chatbot(state:State): \n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values(): \n",
    "            print(\"Agent:\", value[\"messages\"])\n",
    "\n",
    "user_query = \" Who is Charles Bukowski?\"\n",
    "\n",
    "stream_graph_updates(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display \n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "except Exception as e: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding external tools to a chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper \n",
    "from langchain_community.tools import WikipediaQueryRun \n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1)\n",
    "\n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "tools = [wikipedia_tool]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[wikipedia_tool])\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "\n",
    "graph_builder.add_edge('tools', 'chatbot')\n",
    "graph_builder.add_edge(START, 'chatbot')\n",
    "graph_builder.add_edge('chatbot', END)\n",
    "\n",
    "display(Image(graph_builder.compile().get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_tool_responses(user_input: str): \n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}): \n",
    "        for value in event.values(): \n",
    "            print(\"Agent:\", value[\"messages\"])\n",
    "\n",
    "user_query = \"House of lords\"\n",
    "stream_tool_responses(user_query)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver() \n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "def stream_memory_responses(user_input: str):\n",
    "    \n",
    "    config={\"configurable\": {\"thread_id\": \"single_session_memory\"}}\n",
    "    \n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}, config):\n",
    "        for value in event.values():\n",
    "            print(\"Agent:\", value[\"messages\"])\n",
    "\n",
    "\n",
    "user_query = \"What is the Colosseum?\"\n",
    "stream_memory_responses(user_query)\n",
    "user_query = \"Who built it?\"\n",
    "stream_memory_responses(user_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def date_checker(date: str) -> str: \n",
    "    \"\"\"Provide a list of important events that happened on a given date in any format.\"\"\"\n",
    "    try: \n",
    "        answer = llm.invoke(f\"List important historical events that occurred on {date}.\")\n",
    "        return answer.content\n",
    "    except Exception as e: \n",
    "        return f\"Error retrieving events {str(e)}\"  \n",
    "    \n",
    "@tool \n",
    "def is_palindrome(text: str) -> bool: \n",
    "    \"\"\"Check if a given text is a palindrome.\"\"\"\n",
    "    if (text.lower().strip() == text[::-1].lower().strip()):\n",
    "        return \"The text '{text}' is a palindrome.\"\n",
    "    else:\n",
    "        return \"The text '{text}' is NOT a palindrome.\"\n",
    "    \n",
    "\n",
    "tools = [wikipedia_tool, date_checker, is_palindrome]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode \n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "model_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, START, END \n",
    "\n",
    "def should_continue(state: MessagesState): \n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\" \n",
    "    \n",
    "    return END\n",
    "\n",
    "def call_model(state: MessagesState): \n",
    "\n",
    "    last_message = state[\"messages\"][-1] \n",
    "\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return {\"messages\": [AIMessage(content=last_message.total_calls[0][\"response\"])]}\n",
    "\n",
    "    return {\"messages\": [model_with_tools.invoke(state[\"messages\"])]} \n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_node(\"chatbot\", call_model)\n",
    "\n",
    "workflow.add_conditional_edges(\"chatbot\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(START, \"chatbot\")\n",
    "workflow.add_edge(\"tools\", \"chatbot\")\n",
    "workflow.add_edge(\"chatbot\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "#display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BaseML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
