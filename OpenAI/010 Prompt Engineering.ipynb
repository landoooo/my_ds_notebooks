{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e108334-6e43-406a-b31a-07a05b18d9dd",
   "metadata": {},
   "source": [
    "# Prompt engineering \n",
    "\n",
    "Crafting prompt to get what we want.\n",
    "\n",
    "The quality of the answer is correlated to the quality of the prompt \n",
    "\n",
    "Temperature controls the randomnes\n",
    "Max_tokens controls the length \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b5017-ebed-4e33-adf8-12c3a74f4ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eaa764-ae8b-4844-923c-b5ca501d35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt, model='gpt-3.5-turbo',temperature=0): \n",
    "    response = client.chat.completions.create(\n",
    "        model=model, \n",
    "        messages=[\n",
    "            {'role':'user', 'content': prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5c0db-c3d3-4262-9b0e-9bec23884b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_response('Como te encuentras?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050fd248-6597-450a-8c40-6d196ef16f39",
   "metadata": {},
   "source": [
    "# Principles \n",
    "\n",
    "Clear and precise prompts \n",
    "\n",
    "## Appropiate action verbs \n",
    "\n",
    "Write, complete, explain, describe... work well. Understand, think, feel, try, know... dont.\n",
    "\n",
    "\n",
    "## Formulating detailed instructions \n",
    "\n",
    "Provide specific, descriptive and detailed instructions regarding: \n",
    "- context\n",
    "- output text\n",
    "- length (max_tokens is a hard limit, while lenght in words, sentences, paragraphs... in the prompt could be bypassed)\n",
    "- audience\n",
    "\n",
    "\n",
    "## Components \n",
    "\n",
    "Use delimiters like backticks, parenthesis... between the instructions (at the beginning) and the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614205e-5d1b-4fbf-a10c-f751c4e2f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = 'Habia una vez un ni単o que tenia la cabeza como una cebolla.'\n",
    "\n",
    "\n",
    "# Create a prompt that completes the story\n",
    "prompt = f\"\"\"\n",
    "        Complete the story delimited by triple backticks(```) with only two paragraphs in the style of Shakespeare:\n",
    "        ```{story}``` \"\"\"\n",
    "\n",
    "# Get the generated response \n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"\\n Original story: \\n\", story)\n",
    "print(\"\\n Generated story: \\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28cb115-fd6d-4e30-96ab-ecc04ac492c8",
   "metadata": {},
   "source": [
    "# Structured outputs \n",
    "\n",
    "If we want the output to be in a specific format like a table, csv, lit... its important to mention the expected columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69365da-4cfc-4913-9bfd-e31eec7466a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt that completes the story\n",
    "prompt = f\"\"\"\n",
    "            Give me a list of the top 5 action movies with title, ranking and rating in a table\n",
    "         \"\"\"\n",
    "\n",
    "# Get the generated response \n",
    "response = get_response(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c545f-4feb-4242-9571-63c81b6f518d",
   "metadata": {},
   "source": [
    "# Conditional prompts \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd325ab-d7f6-4f3b-bb25-7c50c98635f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='Tengo ganas de ir al ba単o, que la ultima vez que fui fue hace un a単o. Como no vaya pronto atasco el ca単o.'\n",
    "\n",
    "prompt=f\"\"\"You will be provided with a text delimited by ||. \n",
    "    If the text is in spanish, provide a title for it. Otherwise, write 'Queeee???'\n",
    "    ||{text}||\"\"\"\n",
    "\n",
    "print(get_response(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec7dfff-95e7-4d17-aafa-e8f48928d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='I gotta go to the restroom or i would go Boom!'\n",
    "\n",
    "prompt=f\"\"\"You will be provided with a text delimited by ||. \n",
    "    If the text is in spanish, provide a title for it. Otherwise, write 'Queeee???'\n",
    "    ||{text}||\"\"\"\n",
    "\n",
    "print(get_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c483ba99-596f-4a33-8d43-1cb927340eb5",
   "metadata": {},
   "source": [
    "# Few-shot prompting \n",
    "\n",
    "The number of shots may correspond to the task complexity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b33e7a-9b18-4aab-81ae-b628d4ccd29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one-shot prompt\n",
    "prompt = \"\"\"Extract the odd numbers {1, 3, 7, 12, 19} -> {1, 3, 7, 19}\n",
    "Extract the odd numbers from {3, 5, 11, 12, 16} -> \"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb96433-884b-4099-a29a-ffb51cc9b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model = \"gpt-4o-mini\",\n",
    "  # Provide the examples as previous conversations\n",
    "  messages = [{\"role\": \"user\", \"content\": \"The product quality exceeded my expectations\"},\n",
    "              {\"role\": \"assistant\", \"content\": \"1\"},\n",
    "              {\"role\": \"user\", \"content\": \"I had a terrible experience with this product's customer service\"},\n",
    "              {\"role\": \"assistant\", \"content\": \"-1\"},\n",
    "              # Provide the text for the model to classify\n",
    "              {\"role\": \"user\", \"content\": \"The price of the product is really fair given its features\"}\n",
    "             ],\n",
    "  temperature = 0\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19303351-7eb9-4e81-91ae-711ee91c736b",
   "metadata": {},
   "source": [
    "# Multi Step Prompting \n",
    "\n",
    "Breaking a goal into a series of steps. Provides a roadmap to the model.\n",
    "\n",
    "Good for sequential tasks \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea0a51-7ccb-4f3a-a020-49bd3f3e57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single-step prompt to get help planning the vacation\n",
    "prompt = 'Help me planning a beach vacation'\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e839e2-ad66-4206-bd75-010453a7c819",
   "metadata": {},
   "source": [
    "# Chain of Thought Prompting \n",
    "\n",
    "Requires LLMs to provide reasoning steps before giving an answer. Used for complex reasoning tasks. Help reduce model errors. \n",
    "\n",
    "One limitation of this technique is the fact that one missed step with an invalid reasoning will make the whole process to fail.\n",
    "\n",
    "Self-consistency prompting generates multiple chain of thoughts by prompting the model several times. It majority votes to obtain final output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cdf5c7-efdf-4eee-83ac-b750c5b1a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the chain-of-thought prompt\n",
    "prompt = f'''\n",
    "Write my friend's father's age in 10 years, given that he is currently twice my friend's age, and my friend is 20. Write a step by step reasoning.\n",
    "'''\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915bcb1-62ad-4572-81ee-abad9491994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the self_consistency instruction\n",
    "self_consistency_instruction = '''Solve the problem with three experts and combine the results with a majority vote:\n",
    "'''\n",
    "\n",
    "# Create the problem to solve\n",
    "problem_to_solve = \"If you own a store that sells laptops and mobile phones. You start your day with 50 devices in the store, out of which 60% are mobile phones. Throughout the day, three clients visited the store, each of them bought one mobile phone, and one of them bought additionally a laptop. Also, you added to your collection 10 laptops and 5 mobile phones. How many laptops and mobile phones do you have by the end of the day?\"\n",
    "\n",
    "# Create the final prompt\n",
    "prompt = self_consistency_instruction + problem_to_solve\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8498d226-4860-4bec-8edc-00c6c28578fa",
   "metadata": {},
   "source": [
    "# Iterative prompt engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd16c8-f9a1-444b-b3df-be753f31bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine the following prompt\n",
    "prompt = \"Give me the top 10 pre-trained language models\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3e516e-3709-43c4-bf32-64eb9afc07f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine the following prompt\n",
    "prompt = \"Give me the top 10 pre-trained language models. Write the output as a table with the following columns: model name, release year, and owning company\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3dabc6-641e-472a-9b64-d7829df370fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
