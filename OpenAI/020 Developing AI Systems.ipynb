{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18088d60-de6c-43e7-873f-982daa18fcd5",
   "metadata": {},
   "source": [
    "# Structuring an API call \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37068b8-c713-4d47-bfbc-ea4fec60bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os \n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5001748-d24f-4dc2-8872-1fe2cc990535",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages =[{\n",
    "        'role': 'user', \n",
    "        'content': 'Who developed chatgpt?'\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825a484-1fcf-4271-91e6-7250e7d36148",
   "metadata": {},
   "source": [
    "# Challenges on a production environment\n",
    "\n",
    "## Error Handling \n",
    "- Display useful error messages\n",
    "- Alternatives for when the service is unavailable\n",
    "\n",
    "## Moderation and Safety \n",
    "- Control unwanted inputs\n",
    "- Minimizing the risk of data leaks\n",
    "\n",
    "## Testing and validation \n",
    "- Checking for responses that are out of topic\n",
    "- Testing for inconsisten behavior\n",
    "\n",
    "## Communication with External Systems \n",
    "- Calling external functions and APIs\n",
    "- Optimizing response times\n",
    "\n",
    "# Specific Output Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5115633-2135-4658-9e89-8296046a0959",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages =[{\n",
    "        'role': 'user', \n",
    "        'content': 'Give me the best 3 novels of all time in json format'\n",
    "    }]\n",
    ")\n",
    "\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a13bd-fdbf-44f7-ba4f-5356bd2bca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the request\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "   {\"role\": \"user\", \"content\": \"Give me the 3 best graphic novels of all time in json format\"}\n",
    "  ],\n",
    "  # Specify the response format\n",
    "  response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543bdd91-cfb4-4cb5-b595-b52d460a655f",
   "metadata": {},
   "source": [
    "# Handling errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc702dcd-17d0-4f1c-af03-be2b91179818",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='text-davinci-001', \n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"give me the 3 best post rock albums of all time in json format\"\n",
    "        }\n",
    "   ],\n",
    "    response_format='json_object'\n",
    ")\n",
    "\n",
    "Markdown(response.choices[0].content.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0fd7cf-988c-44fe-b0e6-b53c4885da6c",
   "metadata": {},
   "source": [
    "## Connection Errors\n",
    "Common expectable errors on either server or client side are **InternalServerError**, **APIConnectionError** or **APITimeourError**\n",
    "\n",
    "In these cases: \n",
    "- Check connection configuration\n",
    "- Reach out to support\n",
    "\n",
    "## Resource Limits Errors \n",
    "**ConflictError** and **RateLimitError** \n",
    "\n",
    "- Check limit restrictions\n",
    "- Ensure requests are within limits\n",
    "\n",
    "## Authentication errors \n",
    "Wrong, expired or revoked api keys\n",
    "\n",
    "## Bad Request errors\n",
    "Check the expected request documentation for missing keys or typos.\n",
    "\n",
    "\n",
    "# Handling Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67996d94-6792-41c1-ad63-8bd7c1285285",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-4o-mini',\n",
    "        messages= [{\n",
    "            'role': 'user',\n",
    "            'content': 'list five data science professions'\n",
    "        }]\n",
    "    )\n",
    "except openai.AuthenticationError as e:\n",
    "    print(f'OpenAI failed to authenticate: {e}')\n",
    "    pass\n",
    "except openai.RateLimitError as e:\n",
    "    print(f'OpenAI API request exceeded rate limit: {e}')\n",
    "    pass\n",
    "except Exception as e: \n",
    "    print(f'Unable to generate a response. Exception: {e}')\n",
    "    pass \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720dec28-5bac-44d1-b5c3-c0e8c38cb658",
   "metadata": {},
   "source": [
    "# RateErrorLimit \n",
    "\n",
    "The RateLimitError could be caused by: \n",
    "- Too many requests in a short period of time\n",
    "- Too many tokens in the request\n",
    "\n",
    "## Solutions \n",
    "\n",
    "### Retry (short wait between the requests)\n",
    "Retry can be achieved with the python's tenacity library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fcf746-92e6-4270-b99f-6777045a1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import (retry, stop_after_attempt, wait_random_exponential)\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(2))\n",
    "def get_response():\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-4o-mini',\n",
    "        messages= [{\n",
    "            'role': 'user',\n",
    "            'content': 'list five data science professions'\n",
    "        }]\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "get_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b165dd4-c76d-47b0-9161-f9e6938dacbf",
   "metadata": {},
   "source": [
    "### Batching (Processing multiple messages in one request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e212025-f8df-4ab1-b91c-ebf4eced5f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['Pearl Jam', 'Radiohead', 'Sigur Ros']\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        'role': 'system', \n",
    "        'content': '''You are given a series of rock bands and are asked to return \n",
    "        their best album along with the publication year. Provide each answer in the \n",
    "        response as a separate content''',\n",
    "    }\n",
    "]\n",
    "[message.append({'role': 'user', 'content': band}) for band in bands]\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be1b18-a728-4ee8-94aa-9eb861a1d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini', \n",
    "    messages=message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d37180-b40a-41fb-b436-e808b2bce73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5e672a-0a82-45dc-94fa-28f026dab390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:15:20.072963Z",
     "iopub.status.busy": "2024-11-21T14:15:20.072360Z",
     "iopub.status.idle": "2024-11-21T14:15:20.081894Z",
     "shell.execute_reply": "2024-11-21T14:15:20.080564Z",
     "shell.execute_reply.started": "2024-11-21T14:15:20.072930Z"
    }
   },
   "source": [
    "### Reducing the amount of tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87840a-2e95-400d-90c6-df0c376ebb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken \n",
    "\n",
    "encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "prompt = 'tokens can be full words or groups of characters commonly grouped together: tokenization'\n",
    "\n",
    "encoded = encoding.encode(prompt)\n",
    "num_tokens = len(encoded)\n",
    "print(f\"Num tokens: {num_tokens}\")\n",
    "print(f\"encoded: {encoded[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f327771-1f75-470f-8605-1f5ba48a0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"I'd like to buy a shirt and a jacket. Can you suggest two color pairings for these items?\"}\n",
    "\n",
    "# Use tiktoken to create the encoding for your model\n",
    "encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "# Check for the number of tokens\n",
    "num_tokens = len(encoding.encode(input_message['content']))\n",
    "\n",
    "# Run the chat completions function and print the response\n",
    "if num_tokens <= 100:\n",
    "    response = client.chat.completions.create(model=\"gpt-4o-mini\", messages=[input_message])\n",
    "    print(response.choices[0].message.content)\n",
    "else:\n",
    "    print(\"Message exceeds token limit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5e9bc-dd5b-43c9-b723-eefa01cdcaeb",
   "metadata": {},
   "source": [
    "# Defining Function Calling \n",
    "\n",
    "Functions help increasing the reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e9731-5070-4f31-92fe-a338761ba2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_definition = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'real_estate_info',\n",
    "            'description': 'Get the information about homes for sale from the body of the input text',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'home type': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'Home type'\n",
    "                    },\n",
    "                    'location': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'Location'\n",
    "                    },\n",
    "                    'price': {\n",
    "                        'type': 'integer',\n",
    "                        'description': 'Price'\n",
    "                    },\n",
    "                    'bedrooms': {\n",
    "                        'type': 'integer',\n",
    "                        'description': 'Number of bedrooms'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "message_listing =[\n",
    "                    {'role': 'system',\n",
    "                     'content': \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"},\n",
    "                    {'role': 'user',\n",
    "                    'content': 'Step into this beautiful two-story, single-family home located in Springfield, USA, priced at $350,000. This charming property features 4 bedrooms, 2.5 bathrooms, a spacious living room with a cozy fireplace, a modern kitchen with stainless steel appliances, and a large backyard perfect for family gatherings. The master bedroom includes an en-suite bathroom and a walk-in closet. Enjoy the convenience of an attached two-car garage and a recently updated HVAC system. Located near top-rated schools, parks, and shopping centers, this home is ideal for families looking for comfort and convenience.'}\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199ce55-4fc4-4bd8-8234-1ca5995a0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # Add the message\n",
    "    messages = message_listing,\n",
    "    # Add your function definition\n",
    "    tools=function_definition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8700657-ebe3-4b5a-8482-864c3c1064f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36038218-d0e6-4880-96fd-86b3fece65e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T17:41:38.624887Z",
     "iopub.status.busy": "2024-11-22T17:41:38.623133Z",
     "iopub.status.idle": "2024-11-22T17:41:38.635562Z",
     "shell.execute_reply": "2024-11-22T17:41:38.631089Z",
     "shell.execute_reply.started": "2024-11-22T17:41:38.624820Z"
    }
   },
   "source": [
    "## Parallel function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40485904-c4fb-4bc2-be60-e381535c82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_definition.append({\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'real_estate_adj',\n",
    "            'description': 'Get the main adjective used in the description',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'adjective': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'Main adjective used in the description'\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea4be3-da6f-49b7-bdfb-91272082411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # Add the message\n",
    "    messages = message_listing,\n",
    "    # Add your function definition\n",
    "    tools=function_definition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71b7ec-c1fb-4f90-aa24-5f272b109617",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892b5ab-aa29-4d79-84ac-797f30e2cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.tool_calls[1].function.arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208e1b2-fb94-415a-9916-aaebc66f943e",
   "metadata": {},
   "source": [
    "If we end up having many function definition we could allow the LLM to pick the ones to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44274cb9-b64e-41e3-8dc2-25bd10ea91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = message_listing,\n",
    "    tools=function_definition, \n",
    "    tool_choice='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b60838-c9af-4a51-885f-bbbed1f3e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "print(response.choices[0].message.tool_calls[1].function.arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da275a59-ce95-44c8-80c8-b1395938b8d5",
   "metadata": {},
   "source": [
    "If we want to be the ones choosing the function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b5a9c-0218-4e70-9e7b-e6c79a122d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = message_listing,\n",
    "    tools=function_definition, \n",
    "    tool_choice={\n",
    "        'type': 'function', \n",
    "                'function': {'name': 'real_estate_info'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70149e7f-183e-452f-a33f-31d829e093dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "print(response.choices[0].message.tool_calls[1].function.arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd8b04-1b6c-480a-8cdc-31380428f5ae",
   "metadata": {},
   "source": [
    "Sometimes the model makes assumptions about values that could end up being returned. To avoid this behaviour, we can use a system message asking the model not to do any assumptions.\n",
    "\n",
    "When using this approach we have to be cautious since the response could contain empty dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9b2f2-b7c3-4705-b510-ce511e7c58e1",
   "metadata": {},
   "source": [
    "# Calling external APIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9b97f-094c-41de-bf64-e02eb64dd66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "def get_artwork(keyword): \n",
    "    url = 'https://api.artic.edu/api/v1/artworks/search'\n",
    "    querystring = {'q': keyword} \n",
    "    response = requests.request('GET', url, params=querystring) \n",
    "    return response.text \n",
    "\n",
    "\n",
    "get_artwork('modern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb44d4-6b3a-4610-bdbc-54e0ce9577aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_definition = [\n",
    "    {\n",
    "        'type': 'function', \n",
    "        'function': {\n",
    "            'name': 'get_artwork', \n",
    "            'description': ' This function calls the Art Institute of chicago api to find artwork that matches a keyword', \n",
    "            'parameters': {\n",
    "                'type': 'object', \n",
    "                'properties': {\n",
    "                    'artwork keyword': {\n",
    "                        'type': 'string', \n",
    "                        'description': 'The keyword to be passed to the get_artwork function'\n",
    "                    }\n",
    "                }\n",
    "            }, \n",
    "            'result': {'type': 'string'}\n",
    "            \n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-4o-mini', \n",
    "    messages = [\n",
    "        {'role': 'system', \n",
    "        'content': 'You are an AI assistant, a specialist in history of art. You should interpret the user prompt, and based on it extract one keyword for recommending artwork related to their preference.'}, \n",
    "        {'role': 'user', \n",
    "        'content': 'I dont have much time to visit the museum and would like some recommendations. I like the seaside and quite places.'}    \n",
    "    ], \n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd03617-ba89-4cb0-bd8a-9f841b95b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d4a7f-71a2-4843-9bff-d57821bacdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "if response.choices[0].finish_reason=='tool_calls': \n",
    "    function_call = response.choices[0].message.tool_calls[0].function \n",
    "    if function_call.name=='get_artwork': \n",
    "        artwork_keyword = json.loads(function_call.arguments)['artwork keyword']\n",
    "        artwork = get_artwork(artwork_keyword)\n",
    "        if artwork: \n",
    "            print(f\"Here are some recommendations: {[i['title'] for i in json.loads(artwork)['data']]}\")\n",
    "        else: \n",
    "            print('Apoogies, I couldnt make any recommendations based on the request')\n",
    "    \n",
    "    else: \n",
    "        print('apologies, I couldnt find any artwork.')\n",
    "else: \n",
    "    print('I am sorry but I could not understand your request.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffee96-f95a-4ea4-8fa2-194bf9b6dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].finish_reason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f21ecc-d1e8-4541-ae13-72e28a90477c",
   "metadata": {},
   "source": [
    "# Moderation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5584b9-fbba-483a-a6b2-1adc6e3abf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Can you show some example sentences in the past tense in French?\"\n",
    "\n",
    "# Use the moderation API\n",
    "moderation_response = client.moderations.create(\n",
    "    model = 'text-moderation-latest',\n",
    "    input = message\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(moderation_response.results[0].categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce19bf-8b97-4035-8ed4-389d30a9a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"Can you recommend a good restaurant in Berlin?\"\n",
    "\n",
    "# Write the system and user message\n",
    "messages = [\n",
    "    {'role': 'system',\n",
    "    'content': 'You are a chatbot providing advice to tourists visiting Rome. Keep the topics limited to only covering questions about food and drink, attractions, history and things to do around the city. Check the user question and if it is allowed, provide a reply, otherwise provide the message: \"Apologies, but I am not allowed to discuss this topic.\"'},\n",
    "    {'role': 'user',\n",
    "    'content': user_request}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", messages=messages\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af999df-9cab-4f21-b9d0-623906e84830",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "Adversarial testing is a valid way to identify flaws in the system before release."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23022558-7230-4078-b7d4-ed740685a41b",
   "metadata": {},
   "source": [
    "# End user Ids \n",
    "OpenAI recommends to include unique user ids in the requests so any user violating rules could be identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d087b904-5366-447d-b574-ca18356afaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "\n",
    "# Generate a unique ID\n",
    "unique_id = str(uuid.uuid4())\n",
    "\n",
    "response = client.chat.completions.create(  \n",
    "  model=\"gpt-4o-mini\", \n",
    "  messages=messages,\n",
    "# Pass a user identification key\n",
    "  user= unique_id\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c34a86-e98a-4a94-960c-d053d3ab6cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
