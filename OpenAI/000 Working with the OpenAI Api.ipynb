{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e715c-e5b9-4cef-a1c2-4b4cd66e2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154f177-0df5-4ed3-b011-c0c102591ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    # Write your prompt\n",
    "    prompt=\"In two sentences, how can the OpenAI API be used to upskill myself?\",\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc689ba-707b-494d-9e15-128c4d109bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the response into a dictionary\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2d9ba-8f43-4ee9-b83e-66a00caec42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using an organization can help with limits, billing, etc. \n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  organization='org-4otiQhcm1LBuWdDYRBImSUlI',\n",
    "  project='proj_bAW2JMzoEkGe09EcZZrTQ5oi',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f5219-988e-4ba8-b6ad-6442ed24185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d256dc-2ac4-4057-bcdc-173f89ce066d",
   "metadata": {},
   "source": [
    "# OpenAI Models\n",
    "\n",
    "## Completions \n",
    "\n",
    "- Receive continuation of a prompt\n",
    "- Single Turn Tasks\n",
    "    - Answer quesions\n",
    "    - Classification\n",
    "    - Sentiment Analysis\n",
    "    - Explain Complex Topics\n",
    "\n",
    "When we send a text to a text completion endpoint, the api responds with the text that is *most likely* to complete the prompt. Responses are non-deterministic, though.\n",
    "\n",
    "Sometimes this randomness is not desirable, like in a customer service chatbot. **Temperature** is a parameter ranging from 0 (highly deterministic) to 2 (very random). \n",
    "\n",
    "On top of answering questions, other kinds of tasks where the completions model can help are summarization, text content generation and transformation (find and replace)...\n",
    "\n",
    "The **max_tokens** param helps shape the size of the response and control the price.\n",
    "\n",
    "Classification of sentences or tokens is another capability of the completions model.\n",
    "\n",
    "Depending on the amount of examples provided, our requests can be categorized as:\n",
    "- **Zero shot**: no example\n",
    "\n",
    "These two are colled in-context learning:\n",
    "- **One shot**: one example\n",
    "- **Few shot**: several examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c4a89-fee4-4091-874b-18a023c8582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for temperature in [0,1]:\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        # Write your prompt\n",
    "        prompt=\"In two sentences, how can the OpenAI API be used to upskill myself?\",\n",
    "        max_tokens=100, \n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    print(f\"Temperature {temperature}: {response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca306a8-dc87-484b-93df-4b7ce26efce2",
   "metadata": {},
   "source": [
    "## Chat \n",
    "\n",
    "- Multi-turn conversations\n",
    "  - Ideation\n",
    "  - Customer Support Assistant\n",
    "  - Personal Tutor\n",
    "  - Translations\n",
    "  - Write code\n",
    "- Also performs well single turn tasks\n",
    "\n",
    "One benefit of the chat completions is that they offer better customization through the use of *roles*\n",
    "\n",
    "Another benefit is the instruct models are more expensive than the chat ones.\n",
    "\n",
    "### Roles \n",
    "\n",
    "- **System**: controls assistant's behavior\n",
    "- **User**: instructs the assistant\n",
    "- **Assistant**: response to the user instruction.\n",
    "  - Can also be written by the user to provide examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5080bde-0d3e-48e0-b73c-d1379cbe1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"you are a data science tutor who speaks concisely\"}, \n",
    "              {\"role\": \"user\", \"content\": \"what is the difference between lasso and ridge\"}, \n",
    "             ],\n",
    "    max_tokens=200,\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75903705-02c7-45e2-b395-6aab3667a121",
   "metadata": {},
   "source": [
    "We can provide example messages as a conversation to the system so it can learn how do we want it to interact with us.\n",
    "\n",
    "Storing responses allow us to create back and forth conversations. Thats how chatgpt works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b9226-b396-41df-b55a-9df8fc0585cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "   model=\"gpt-4o-mini\",\n",
    "   # Add a user and assistant message for in-context learning\n",
    "   messages=[\n",
    "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain python lists\"},\n",
    "     {\"role\": \"assistant\", \"content\": \"Python list is a type of python ordered structure that can contain other objects.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
    "   ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f04eb-f5ab-471b-b690-dbddf729fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"}]\n",
    "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
    "\n",
    "for q in user_msgs:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    # Create a dictionary for the user message from q and append to messages\n",
    "    user_dict = {\"role\": \"user\", \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    # Create the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    # Convert the assistant's message to a dict and append to messages\n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f7173-4d94-4887-a5c3-47ba27126132",
   "metadata": {},
   "source": [
    "## Moderation \n",
    "\n",
    "- Checks content for violations of OpenAIs usage policies, including inciting violence or hate speech.\n",
    "- The sensitivity can be customized\n",
    "\n",
    "The categoryScores object of the response of the moderation model gives us fine details about different aspects of the moderation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da03bae-a1e8-425b-9170-7a0f741ed1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# Create a request to the Moderation endpoint\n",
    "response = client.moderations.create(\n",
    "    model='text-moderation-latest',\n",
    "    input='My favorite book is To Kill a Mockingbird.'\n",
    ")\n",
    "\n",
    "# Print the category scores\n",
    "print(response.results[0].category_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e7749-88e8-419d-8aa9-e4517cffc4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(response.results[0].category_scores, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caeb36a-7244-4902-9c61-c5ff666d3fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085400c7-4c2b-4e84-b570-beb69148c72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd725f9-5ee3-40c7-8070-aa76399f7a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b9cba-50bf-44a8-8d64-6211ceb429b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7600f5c8-83fe-4d96-8a9f-62aafee28b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
