{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33e2dc2-8a2a-4b36-abd0-f390533df636",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ea2f97-9474-4e29-9d7c-359a944c2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb41ded-5790-4e25-bf87-0da7db5d03be",
   "metadata": {},
   "source": [
    "## Population vs Sample\n",
    "\n",
    "The **population** is the complete dataset. It doesnt have to refer to people. Typically we dont know what the whole population is.\n",
    "\n",
    "The **sample** is the subset of data you calculate on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878aa95-1a8e-4d0c-8fef-ec2a3eda7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following dataset corresponds to a set of professional evaluations of coffees\n",
    "coffee = pd.read_feather('../data/coffee_ratings_full.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1edbe3-d7f4-4f49-820b-f14f7ee20025",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ede5f-a338-4294-b8f2-e7505b9fef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c8a15-b299-4b56-a3cf-0d33c150ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf940f26-11e2-44dd-92df-84c2efee4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee['variety'] = coffee.variety.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8116767-c7d5-4a7d-80ea-58cd38b602d2",
   "metadata": {},
   "source": [
    "The 1338 observations of the coffee dataset correspond to a sample, and not to the population of the kinds of existing coffee varieties. Yet, in our particular context lets consider this dataset as our population.\n",
    "\n",
    "We can take a sample of this *population* using the *.sample()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a48bd-e859-4e09-86b8-aba3ad5b5def",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_samp = coffee.sample(n=10)\n",
    "coffee_samp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3357db-5b20-44a8-95cb-860cce491f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:49:52.988516Z",
     "iopub.status.busy": "2024-07-28T15:49:52.987452Z",
     "iopub.status.idle": "2024-07-28T15:49:53.000480Z",
     "shell.execute_reply": "2024-07-28T15:49:52.997440Z",
     "shell.execute_reply.started": "2024-07-28T15:49:52.988441Z"
    }
   },
   "source": [
    "## Population parameters and point estimates\n",
    "\n",
    "A **population parameter** is a calculation made on the population dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808113cf-f079-4adb-88a4-214d9df0059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(coffee.aftertaste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092fe9c-3e24-4388-b34e-ea5dc37e40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.aftertaste.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5960ce35-4e67-4499-8175-dfed646c73f7",
   "metadata": {},
   "source": [
    "A **point estimate** or sample statistic is a calculation made on the sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6a8f0-e17d-4ee6-bb90-119a12a07315",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(coffee_samp.aftertaste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940579a9-19ab-45f9-b38e-750684064aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_samp.aftertaste.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0878a92d-2b57-4392-ad7a-cd49d99bed4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:57:56.221062Z",
     "iopub.status.busy": "2024-07-28T15:57:56.220332Z",
     "iopub.status.idle": "2024-07-28T15:57:56.229038Z",
     "shell.execute_reply": "2024-07-28T15:57:56.226062Z",
     "shell.execute_reply.started": "2024-07-28T15:57:56.221020Z"
    }
   },
   "source": [
    "## Convenience sample\n",
    "\n",
    "**Sample bias** is a problem caused when the sample is not representative of the population.\n",
    "Collecting data by the easiest method is called *convenience sampling* and often causes sample bias.\n",
    "\n",
    "Plotting histograms of the sample vs population helps identifying selection bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec8424-b746-44e5-8123-0abb652d4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_bad_samp = coffee.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba6eb6c-97a4-4f8f-aadb-7c9b1e04d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.total_cup_points.hist(bins=np.arange(0,101, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6727362-dba0-47d4-a4bb-3e5cce9ec4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_samp.total_cup_points.hist(bins=np.arange(0,101, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb7ee27-ee2c-4a2a-b321-556aa882af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_bad_samp.total_cup_points.hist(bins=np.arange(0,101, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e8a28-6e96-425e-9d1f-ada608e78527",
   "metadata": {},
   "source": [
    "The random sample seems more representative than the head one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6bf9f-54dd-4b49-b71b-b59fbc55677a",
   "metadata": {},
   "source": [
    "## Pseudo-random number generation\n",
    "\n",
    "Random numbers cannot be known beforehand. True randomness is expensive. Pseudorandomness is a good workaround.\n",
    "\n",
    "Pseudo-random number generation is cheap and fast.\n",
    "Next random number is calculated from the previous one.\n",
    "The first one is calculated from a *seed*.\n",
    "All future values are always the same.##\n",
    "\n",
    "Numpy has many number generators from different statistical distributions under numpy.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9c92b-e3e4-4aa2-b160-fe7605e42d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as random\n",
    "\n",
    "betas = random.beta(a=2, b=2, size=5000)\n",
    "betas\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde97fa-1885-4edf-a411-c5eebbf9df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c79d3-66a5-4bb3-b5cd-06eed1f9d586",
   "metadata": {},
   "source": [
    "Numpy allows us to set the seed so our code is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d193a61-eb11-4b58-a208-5a6e1b991f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b237b11-2251-40cc-b835-c3ef38d5bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "normals = random.normal(loc=2, scale=1.5, size=2000)\n",
    "sns.histplot(normals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b5aae-41af-4a9a-a733-4b2ca45fb48c",
   "metadata": {},
   "source": [
    "## Simple Random and Systematic Sampling \n",
    "\n",
    "### Simple Random Sampling\n",
    "\n",
    "Its like a raffle. We take n random examples, one at a time. The pandas .sample method for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d07ea-f297-4895-9c4a-6c228b6bd939",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = coffee.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235ec25-e349-4987-9fe5-70fe4cb8f04a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T13:32:44.026014Z",
     "iopub.status.busy": "2024-07-30T13:32:44.024630Z",
     "iopub.status.idle": "2024-07-30T13:32:44.039557Z",
     "shell.execute_reply": "2024-07-30T13:32:44.037259Z",
     "shell.execute_reply.started": "2024-07-30T13:32:44.025929Z"
    }
   },
   "source": [
    "The pandas .sample() method accepts the parameter *frac* as well, that represents the fraction of the original dataset to be included in the samplem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28865c0-bad6-4fc2-aa70-fed0c40bd503",
   "metadata": {},
   "source": [
    "### Systematic Random Sampling \n",
    "\n",
    "Picks random samples with a fixed interval. There is no pandas implementation for this, but the .iloc[::interval] works.\n",
    "The systematic random sampling is only safe when there is no pattern in the data. Sampling the whole dataset avoids problems caused by patterns in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f4af6-0570-48b6-8fb6-12e59b8a8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(coffee)\n",
    "sample_size = 10\n",
    "interval = size//sample_size\n",
    "sample_sys = coffee[::interval]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d86bddf-ad56-4dd5-874f-ed026cf18eed",
   "metadata": {},
   "source": [
    "sampling the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae7113-d75d-49d9-b76b-e801eceef5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = coffee.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88dc741-f69d-40e8-8d4f-e5d23825782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c0790-b402-4c04-8117-f1b0e45dbb31",
   "metadata": {},
   "source": [
    "## Stratified and weighted random sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574bb42-e16b-457c-991e-a6d2eb2d812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.country_of_origin.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beffdbe-5385-48c4-8167-05dbc4fcb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_sample = coffee.sample(frac=0.1, random_state=42)\n",
    "coffee_sample.country_of_origin.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd749119-17c4-4f67-9ec2-6a521615de72",
   "metadata": {},
   "source": [
    "If we care about the proportions of each category in the sample, being closer to the ones of the original population, we can group by before sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e274c-db2d-47ef-95f9-b4259f002364",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_strat = coffee.groupby(\"country_of_origin\").sample(frac=0.1, random_state=42)\n",
    "coffee_strat.country_of_origin.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db3c6f9-55ba-4a89-acb2-850a63b08b54",
   "metadata": {},
   "source": [
    "If we want the same amount of elements by category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906d7ac-45be-464d-800d-1438524387bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_strat_eq = coffee.groupby(\"country_of_origin\").sample(n=1, random_state=42)\n",
    "coffee_strat_eq.country_of_origin.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c9233-49ca-48c6-a1e5-d5e68de292d8",
   "metadata": {},
   "source": [
    "In this dataset, there are countries with only one observation, so we cannot have more than 1 per group if we dont do the sampling with Replacement.\n",
    "\n",
    "Another way of doing sampling is taking into account weights: adding a column with weights to the dataframe and passing it to the sampling method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7759da6b-7b43-4a6f-97f8-a54c61b96b0d",
   "metadata": {},
   "source": [
    "## Cluster Sampling\n",
    "\n",
    "The problem with stratified samping is we need to collect data from each group. This could be a problem in terms of time and/or money.\n",
    "\n",
    "When collecting data is expensive, we can use **cluster sampling**\n",
    "\n",
    "Cluster sampling uses simple random sampling to pick some subgroups and use simple random sampling on those subgroups.\n",
    "\n",
    "Cluster sampling is an example of multistage sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2c4fb-19f2-4ac9-a016-1ff6b1519be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "varieties_pop = list(coffee.variety.unique())\n",
    "varieties_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c9e8e-1646-442e-9c3b-a696075638fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1:\n",
    "import random\n",
    "\n",
    "varieties_samp = random.sample(varieties_pop, k=3)\n",
    "varieties_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca25bb3-39b7-4c48-b3e9-84201513b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2:\n",
    "variety_condition = coffee.variety.isin(varieties_samp)\n",
    "coffee_cluster = coffee[variety_condition]\n",
    "\n",
    "coffee_cluster['variety'] = coffee_cluster['variety'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb9190-b535-4095-a057-63884fbc819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_cluster.groupby('variety').sample(n=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18828013-7e26-4534-a33e-024b3b5c476c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T13:31:23.044034Z",
     "iopub.status.busy": "2024-07-30T13:31:23.043279Z",
     "iopub.status.idle": "2024-07-30T13:31:23.053473Z",
     "shell.execute_reply": "2024-07-30T13:31:23.051943Z",
     "shell.execute_reply.started": "2024-07-30T13:31:23.043991Z"
    }
   },
   "source": [
    "### Relative Error of point estimates\n",
    "\n",
    "How does the size of the sample impact the accuracy of the point estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883234ea-a6a8-4b4c-a9c0-4e78b9f5d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.total_cup_points.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247ba1f-1325-4a8c-a589-31dea9a618a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.total_cup_points.sample(n=10, random_state=2024).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984d5be-0989-4cb0-9f52-59326a764f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.total_cup_points.sample(n=100, random_state=2024).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb7569-fe55-46d0-a52c-a70796df6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.total_cup_points.sample(n=1000, random_state=2024).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baeb13b-0761-4eda-83a9-18f9791bd0e9",
   "metadata": {},
   "source": [
    "In general, larger samples sizes gives us more accurate estimations of the populations parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a876aaa-1121-4ed2-9423-a3b7e772274d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T14:42:43.540086Z",
     "iopub.status.busy": "2024-07-30T14:42:43.538350Z",
     "iopub.status.idle": "2024-07-30T14:42:43.552344Z",
     "shell.execute_reply": "2024-07-30T14:42:43.550359Z",
     "shell.execute_reply.started": "2024-07-30T14:42:43.540008Z"
    }
   },
   "source": [
    "The **relative error** is calculated as:\n",
    "\n",
    "$$\n",
    "relativeErrorPctg = 100 * abs(populationParameter - sampleParameter) / populationParameter\n",
    "$$\n",
    "\n",
    "The relative error decreases as the sample size increases. The relative error is quite noisy too, meaning that adding or removing a couple of observations to the sample can have a huge impact in the relative error. Another property of the relative error is that it decreases to zero (when the sample size = population)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685b745-4a9b-4518-9bcf-99a4e52bbd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "popMean = coffee.total_cup_points.mean()\n",
    "rel_errors = []\n",
    "sample_sizes = np.arange(1, len(coffee))\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    sample_mean = coffee.total_cup_points.sample(n=sample_size).mean()\n",
    "    rel_errors.append(100*np.abs(sample_mean-popMean)/popMean)\n",
    "\n",
    "sns.lineplot(x=sample_sizes, y=rel_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce06dc73-2ee8-41f6-b2f3-35e989917549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:05:39.525102Z",
     "iopub.status.busy": "2024-07-30T15:05:39.524475Z",
     "iopub.status.idle": "2024-07-30T15:05:39.530602Z",
     "shell.execute_reply": "2024-07-30T15:05:39.529597Z",
     "shell.execute_reply.started": "2024-07-30T15:05:39.525059Z"
    }
   },
   "source": [
    "## Creating a sampling distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2463f-4061-4dbd-82d0-dc6d20ad745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an empty list\n",
    "mean_rates_5 = []\n",
    "mean_rates_50 = []\n",
    "mean_rates_500 = []\n",
    "# Loop 500 times to create 500 sample means\n",
    "for i in range(500):\n",
    "\tmean_rates_5.append(coffee.total_cup_points.sample(n=5).mean())\n",
    "\tmean_rates_50.append(coffee.total_cup_points.sample(n=50).mean())\n",
    "\tmean_rates_500.append(coffee.total_cup_points.sample(n=500).mean())\n",
    "\n",
    "# Create a histogram of the 500 sample means\n",
    "plt.hist(mean_rates_5, bins=20)\n",
    "plt.title('Sampling distribution of the mean for samples with 5 elements')\n",
    "plt.show()\n",
    "plt.hist(mean_rates_50, bins=20)\n",
    "plt.title('Sampling distribution of the mean for samples with 50 elements')\n",
    "plt.show()\n",
    "plt.hist(mean_rates_500, bins=20)\n",
    "plt.title('Sampling distribution of the mean for samples with 500 elements')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf88a989-df4d-4910-aa3e-4ca5e8ebdc7b",
   "metadata": {},
   "source": [
    "## Approximate Sampling Distributions\n",
    "\n",
    "Sometimes we cannot handle the exact sample distribution due to its size. In that case, we can perform an approximate sampling distribution. Its parameters can help us estimate the exact ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa18d7d-ebb8-46cb-b811-dfbdb9105d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def expand_grid(data_dict):\n",
    "   rows = itertools.product(*data_dict.values())\n",
    "   return pd.DataFrame.from_records(rows, columns=data_dict.keys())\n",
    "\n",
    "# Expand a grid representing 5 8-sided dice\n",
    "dice = expand_grid(\n",
    "  {'die1': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die2': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die3': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die4': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "   'die5': [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "  })\n",
    "\n",
    "# Add a column of mean rolls and convert to a categorical\n",
    "dice['mean_roll'] = (dice['die1'] + dice['die2'] + \n",
    "                     dice['die3'] + dice['die4'] + \n",
    "                     dice['die5']) / 5\n",
    "dice['mean_roll'] = dice['mean_roll'].astype('category')\n",
    "\n",
    "# Draw a bar plot of mean_roll\n",
    "dice['mean_roll'].value_counts(sort=False).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a705c-2c39-4776-9d92-397bd51836d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample one to eight, five times, with replacement\n",
    "five_rolls = np.random.choice(list(range(1, 9)), size=5, replace=True)\n",
    "\n",
    "# Print the mean of five_rolls\n",
    "print(five_rolls.mean())\n",
    "\n",
    "# Replicate the sampling code 1000 times\n",
    "sample_means_1000 = []\n",
    "for i in range(1000):\n",
    "    sample_means_1000.append(\n",
    "  \t\tnp.random.choice(list(range(1, 9)), size=5, replace=True).mean()\n",
    "    )\n",
    "    \n",
    "# Draw a histogram of sample_means_1000 with 20 bins\n",
    "plt.hist(x=sample_means_1000, bins=10)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa303548-f3f5-4021-baae-ff1b4d121e8c",
   "metadata": {},
   "source": [
    "The shape of the approximate sampling one is pretty similar to the one of the exact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de4650-3082-4292-b28e-f827db560967",
   "metadata": {},
   "source": [
    "## Standard errors and the Central Limit Theorem\n",
    "\n",
    "The average of independent samples have approximately normal distributions.\n",
    "\n",
    "As the sample size increases:\n",
    "- The distribution of the averages gets closer to being normally distributed\n",
    "- The width of the sampling distribution gets narrower\n",
    "- The mean sample mean gets closer to the population mean\n",
    "- The standard deviation sample mean decreases  \n",
    "    -> Specify ddof=0 when calculating std() on populations and ddof=1 with samples.\n",
    "- Estimate the population std by multiplying the standard deviation sample mean by the sqrt of the sample size.\n",
    "\n",
    "The standard deviation of the sampling distribution, aka **Standard Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d5acb-f917-4901-a813-802e887d54b6",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "\n",
    "Sampling with replacement (resampling), where each observation can be taken multiple times VS sampling without replacement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834261cc-03cf-400f-8bd2-a4d8f6efd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42724949-af19-4adc-85e1-01c61ff44168",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108c8e4-cf24-4bde-9653-e59738101a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655b657-521a-434f-af72-057426b5d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_resamp = coffee.sample(frac=1, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b16b91-f72b-43ec-835b-24677dfbb7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_resamp.index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de381d3d-c7a9-4762-9940-b18d4443e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_resamp.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337dd26-f1eb-4998-8e11-107db9c7f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coffee)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168fe1c-1c13-4e6e-8a61-609c229952eb",
   "metadata": {},
   "source": [
    "Setting frac to 1 produces a sample of the same size as the original dataset, but, since replace is true, there could be repetitions of observations, leaving some of the observations out of the resampled dataset.\n",
    "\n",
    "**Bootstrapping** is the opposite of sampling from a population:\n",
    "When doing sampling we go from a population to a smaller sample. When doing bootstrapping, we build up a theoretical population from a sample.\n",
    "\n",
    "Bootstrapping process:\n",
    "- Make a resample **of the same size as the original sample**\n",
    "- Calculate the statistic of interest for this bootstrap sample\n",
    "- Repeat steps 1 and 2 many times\n",
    "\n",
    "The resulting statistics are bootstrap statistics and they form a bootstrap distribution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a4f3e-b5f7-494f-9784-64f9c2fb69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_sample = coffee.sample(n=100)\n",
    "\n",
    "mean_flavors_1000 = [] \n",
    "for i in range(1000):\n",
    "    mean_flavors_1000.append(np.mean(coffee_sample.sample(frac=1, replace=True)['flavor']))\n",
    "\n",
    "plt.hist(mean_flavors_1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0743dfc-6330-4bad-b6f1-154e10b24af8",
   "metadata": {},
   "source": [
    "Histogram of the bootstrap distribution of the sample mean. Close to a normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c99d2-aa96-4ef2-b68c-451798faae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.flavor.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e1e2a-c4e0-4b9a-810a-9a78dbc519a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mean_flavors_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e678af15-7c10-4309-981e-2dbf33d4680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_sample.flavor.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872fc35a-9652-4fc7-baa8-c078abda58ec",
   "metadata": {},
   "source": [
    "The bootstrap distribution mean is usually close to the sample mean. If the sample wasnt a good representation of the population, then, the bootstrap distribution mean may not be a good estimate of the population mean.\n",
    "Bootstrap cannot correct any potential bias from sampling\n",
    "\n",
    "If we calculate the sample std and the estimated population std using the bootstrap distribution (with ddof=1), we can see huge differences.\n",
    "\n",
    "Standard error is the standard deviation of the statistic of interest.\n",
    "\n",
    "Standard error times sqrt of the sample size estimates the population standard deviation.\n",
    "\n",
    "\n",
    "TO REVIEW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2d5538-efe1-403e-b68c-96f9d61cef7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T10:05:21.928417Z",
     "iopub.status.busy": "2024-07-31T10:05:21.927117Z",
     "iopub.status.idle": "2024-07-31T10:05:21.937807Z",
     "shell.execute_reply": "2024-07-31T10:05:21.935875Z",
     "shell.execute_reply.started": "2024-07-31T10:05:21.928333Z"
    }
   },
   "source": [
    "## Confidence Intervals\n",
    "\n",
    "*Values within one standard deviation of the mean* includes a large number of values from each of these distributions.\n",
    "\n",
    "Sometimes a point estimate is not enough or not ideal for our purpose and giving a range of possible values centered in the point estimate is simply better since it will indicate how sure we are about that estimate.\n",
    "\n",
    "In a normal distribution, if we use as a range the mean +/- 1 std (ddof=1) we see that there are plenty of observations falling outside of the range.\n",
    "\n",
    "If we want to include 95% of the observations we could use quantiles (0.025 to 0.975)\n",
    "\n",
    "Another technique to calculate the confidence interval, named Standard Error Method, is based on the quantiles and uses the Inverse Cumulative Distribution Function:\n",
    "The Probability Density Function of a normal distribution is the well known bell curve.\n",
    "The Cumulative Distribution Function is the integration of the PDF, to get the area under the bell curve.\n",
    "The Inverse CDF flips the x and y axes and its implemented with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cebddb-6d46-4e37-855e-75978fae4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "quantile=0.025\n",
    "\n",
    "norm.ppf(quantile, loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8103f3ca-9361-4fed-983b-602261f77d70",
   "metadata": {},
   "source": [
    "It provides the x value in the bell curve for the indicated quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87417658-84b1-4c4f-a56f-6d6c506ddf79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
