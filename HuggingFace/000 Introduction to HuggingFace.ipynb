{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9f077b-5a3e-4110-a165-180e95c6d5bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T19:21:45.742875Z",
     "iopub.status.busy": "2024-10-14T19:21:45.741401Z",
     "iopub.status.idle": "2024-10-14T19:21:46.077879Z",
     "shell.execute_reply": "2024-10-14T19:21:46.077394Z",
     "shell.execute_reply.started": "2024-10-14T19:21:45.742806Z"
    }
   },
   "source": [
    "!!!! Numerous issues on M1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec028c92-8d57-47e0-9e75-c4650e09c584",
   "metadata": {},
   "source": [
    "# Loading the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650de626-f6dd-42d4-8066-7e883e143dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi \n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "api = HfApi() \n",
    "\n",
    "list(api.list_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f5234-b790-4ff9-9df7-cff0ad24d005",
   "metadata": {},
   "source": [
    "# Filtering Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4161243-5826-408d-97fc-39026da08459",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()\n",
    "\n",
    "models = api.list_models(\n",
    "\ttask=\"image-classification\",\n",
    "\tlibrary=\"pytorch\",\n",
    "\ttrained_dataset=\"imagenet\",\n",
    ")\n",
    "\n",
    "\n",
    "# Store as a list\n",
    "modelList = list(models)\n",
    "\n",
    "print(modelList[0].modelId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5ebac-c3d9-457e-88c1-c617a12755cd",
   "metadata": {},
   "source": [
    "# Downloading a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f5129-67c6-4b80-838b-1e61caf29786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "modelId = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Instantiate the AutoModel class\n",
    "model = AutoModel.from_pretrained(modelId)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory=f\"models/{modelId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6119242-95b7-46a0-9281-518d276d2e80",
   "metadata": {},
   "source": [
    "# Woking with Datasets\n",
    "\n",
    "Datasets can be consulted [here](https://huggingface.co/datasets). Each dataset has a dataset card, detailing itself.\n",
    "\n",
    "The library *dataset* allows access, download, mutate, use and share all these datasets straight away. \n",
    "\n",
    "These datasets are usually quite big. Check them before downloading and mind the disk space.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d01caa-1f62-4391-bf31-fdfba8851442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset_builder\n",
    "\n",
    "data_builder = load_dataset_builder(\"derenrich/wikidata-en-descriptions-small\")\n",
    "\n",
    "print('Description: ', data_builder.info.description)\n",
    "print('Features: ', data_builder.info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d27891-eca2-4b2e-b739-6c94cdffe5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "data=load_dataset('imdb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7129e-77b3-48cc-b549-df0bc94900fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With split parameter\n",
    "data = load_dataset('imdb', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea849f-7bef-4553-9734-38130c5e0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameter \n",
    "#data=load_dataset('wikipedia', '20231101.en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e217457a-0d20-41ce-8b3a-c62725c1f96b",
   "metadata": {},
   "source": [
    "This datasets are in apache arrow format -> efficient processing on large data and faster querying\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d6f6d-3a80-4503-8ba6-ba5699a776ef",
   "metadata": {},
   "source": [
    "# Pipelines \n",
    "\n",
    "Autoclasses are general classes for using Models, tokenizers, Configurations, Processors, Feature extractors. They are flexible and direct.\n",
    "\n",
    "## AutoModels \n",
    "\n",
    "They are Auto classes to directly download a model \n",
    "\n",
    "AutoModel class for each type of task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359791f-c90a-416f-9f69-c2c8565e6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification \n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased-finetuned-sst-2-english'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad94d8a-6e64-4afe-b23b-bf74131a952a",
   "metadata": {},
   "source": [
    "## AutoTokenizers\n",
    "\n",
    "Prepare text input data.\n",
    "\n",
    "Recommended to use the tokenizer paired with the model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f132ef-d3a2-47e6-8be5-350eb29dac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'distilbert-base-uncased-finetuned-sst-2-english'    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b55e474-88aa-4b6d-82f1-7a0a6403427f",
   "metadata": {},
   "source": [
    "## Pipeline Module \n",
    "\n",
    "Contains all task-specific steps \n",
    "\n",
    "Best for quickly performing tasks \n",
    "\n",
    "### Task Pipelines \n",
    "\n",
    "contains task specific pipeline for each task. These task pipelines leverage Auto classes. They download model and relevant processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108e4b2-a2ff-4672-80f8-8b4c0972b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "from transformers import (\n",
    "    SummarizationPipeline, \n",
    "    TextClassificationPipeline, \n",
    "    AudioClassificationPipeline,\n",
    "    ImageSegmentationPipeline, \n",
    "    QuestionAnsweringPipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc3950-7d27-4f4e-a9a7-d766643b5e39",
   "metadata": {},
   "source": [
    "### Creating a pipeline \n",
    "\n",
    "When creating a pipeline you can specify a task or a model. This will end up in hf using default values for the missing param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd43ab-55a4-4f0c-a97d-98887d6b94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipelne = pipeline(task='text-classification') \n",
    "\n",
    "my_pipeline = pipeline(model='distilbert-base-uncased-finetuned-sst-2-english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e93b4-d10c-4e67-9bbc-d1397c66b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipelne = pipeline(task='text-classification',\n",
    "                      model='distilbert-base-uncased-finetuned-sst-2-english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1fc50f-ca1c-498f-a316-667b798e50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased-finetuned-sst-2-english'\n",
    ")\n",
    "\n",
    "my_pipeline = pipeline(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2e5ab-492b-427f-ab29-ecacaa3d72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "my_pipeline = pipeline(task = 'text-classification', \n",
    "                        model='distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41fc6f-a347-4990-b0f7-a4f7bb03c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'Hi, welcome to this course'\n",
    "\n",
    "my_pipeline(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e311adc-5d31-4b2d-a5cc-531ccf541213",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'This course is pretty good, I guess.' \n",
    "\n",
    "# Import pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Create the task pipeline\n",
    "task_pipeline = pipeline(task='sentiment-analysis')\n",
    "\n",
    "# Create the model pipeline\n",
    "model_pipeline = pipeline(model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Predict the sentiment\n",
    "task_output = task_pipeline(input)\n",
    "model_output = model_pipeline(input)\n",
    "\n",
    "print(f\"Sentiment from task_pipeline: {task_output[0]['label']}; Sentiment from model_pipeline: {model_output[0]['label']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a49e2b1-dfac-47cc-9a59-93f120b2e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Download the model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Create the pipeline\n",
    "sentimentAnalysis = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Predict the sentiment\n",
    "output = sentimentAnalysis(input)\n",
    "\n",
    "print(f\"Sentiment using AutoClasses: {output[0]['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831885c-c769-432c-9ed6-fbd5d6765cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "distil_pipeline = pipeline(task=\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Predict the sentiment\n",
    "distil_output = distil_pipeline(input)\n",
    "\n",
    "# Create the second pipeline and predict the sentiment\n",
    "bert_pipeline = pipeline(model=\"kwang123/bert-sentiment-analysis\", task=\"sentiment-analysis\")\n",
    "bert_output = bert_pipeline(input)\n",
    "\n",
    "print(f\"Bert Output: {bert_output[0]['label']}\")\n",
    "print(f\"Distil Output: {distil_output[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee077060-8d28-47da-adb8-04348b0e92bf",
   "metadata": {},
   "source": [
    "# Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3191ce-f4af-4d2f-a258-d67a274283af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "print(tokenizer.backend_tokenizer.normalizer.normalize_str('HI, whát are You doing  ?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c44fb6f-abca-4a09-b0e5-90bb02a7724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, DistilBertTokenizer\n",
    "\n",
    "# Download the gpt tokenizer\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Tokenize the input\n",
    "gpt_tokens = gpt_tokenizer.tokenize(input)\n",
    "\n",
    "# Repeat for distilbert\n",
    "distil_tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "distil_tokens = distil_tokenizer.tokenize(text=input)\n",
    "\n",
    "# Compare the output\n",
    "print(f\"GPT tokenizer: {gpt_tokens}\")\n",
    "print(f\"DistilBERT tokenizer: {distil_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3decab41-b6ae-47fa-96ed-1e42fa6d0a75",
   "metadata": {},
   "source": [
    "# Text Classification \n",
    "\n",
    "Text classifiers assing a set of predefined categories to a text. Ambiguity, sarcasm, irony, multiple languages... represent challenges of this discipline.\n",
    "\n",
    "## Sentiment analysis\n",
    "\n",
    "Categorizes in positive or negative depending on the emotional charge of the text. \n",
    "\n",
    "## Question Natural Language Inference (QNLI) \n",
    "\n",
    "Determines if the text (premise) contains sufficient information to answer a question. Categories are: \n",
    "- Entailment (yes, the text contains that info)\n",
    "- Not entailment (no)\n",
    "- Neutral (no relationship between the question and the text)\n",
    "\n",
    "## Topic modeling\n",
    "\n",
    "Assings labels to text dending on the subject they talk about \n",
    "\n",
    "## Grammatical correctness \n",
    "\n",
    "Categories are acceptable or not acceptable \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f85a9-52ee-4287-a346-299ba7f46f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "# without any specified task, it will default to sentiment analysis \n",
    "classifier = pipeline(task='text-classification')\n",
    "\n",
    "print(classifier('I dont like this notebook'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4056b4-dfae-4551-9419-4c6d0ba63b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "classifier = pipeline(task='text-classification',\n",
    "                      model='abdulmatinomotoso/English_Grammar_Checker'\n",
    "                     )\n",
    "\n",
    "string_0 = 'Me doesnt like these notebook'\n",
    "string_1 = 'I dont like this notebook'\n",
    "print(string_0, classifier(string_0))\n",
    "print(string_1, classifier(string_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9105b5-613d-410f-84b9-66d66122c4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b9132-c2c7-4360-89d3-668a6eb3c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "classifier = pipeline(task='text-classification',\n",
    "                      model='cross-encoder/qnli-electra-base'\n",
    "                     )\n",
    "\n",
    "string_0 = 'Where is Seattle located?, Seattle is located in Washington state.'\n",
    "string_1 = 'Where is Seattle located?, I like turtles.'\n",
    "print(string_0, classifier(string_0))\n",
    "print(string_1, classifier(string_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9edd4d-dfeb-4732-8c98-961dc658c387",
   "metadata": {},
   "source": [
    "## Zero shot classification \n",
    "\n",
    "Thanks to transfer learning, there are models who can categorize text into unseen labels, without an specific training. Very useful if we dont have the resources/time to train a new model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774475c4-a846-4195-9be6-b73da22fb64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task='zero-shot-classification', \n",
    "                     model='facebook/bart-large-mnli')\n",
    "\n",
    "text = 'Wikipedia earlier this month released its list of the 25 most viewed...'\n",
    "candidate_labels = ['politics', 'science', 'technology']\n",
    "\n",
    "output = classifier(text, candidate_labels)\n",
    "\n",
    "print(output['labels'][0])\n",
    "print(output['scores'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6814161-9a7f-462d-ac91-b829b6a8762c",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "\n",
    "Can be extractive (reusing pieces) or abstractive (generating new text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1881a47-accf-408c-8cdb-24fbd10fd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''Data science is an interdisciplinary field that combines various domains such as statistics, computer science, machine learning, and domain expertise to extract meaningful insights from data. As the world becomes increasingly data-driven, organizations are leveraging data science to inform decision-making, optimize operations, and gain competitive advantages. This rapidly evolving field has become a cornerstone for businesses in diverse industries, including finance, healthcare, marketing, technology, and more.\n",
    "\n",
    "Foundations of Data Science\n",
    "\n",
    "At its core, data science involves the application of scientific methods to data. This typically involves five key stages:\n",
    "\n",
    "\t1.\tData Collection: Gathering data is the starting point of any data science project. Data can come from a variety of sources, such as databases, IoT sensors, websites, social media platforms, and internal systems. This data can be structured (like data in databases) or unstructured (such as text, images, and videos).\n",
    "\t2.\tData Cleaning and Preprocessing: Once data is collected, it often needs cleaning. Real-world data is often noisy, incomplete, or inconsistent. Techniques such as handling missing values, correcting data types, removing duplicates, and normalization are used to prepare the data for analysis. This step is crucial because the quality of the data can directly impact the quality of the insights derived from it.\n",
    "\t3.\tExploratory Data Analysis (EDA): After cleaning, the next step is to understand the data through exploratory data analysis. Visualization tools and statistical methods are used to summarize key patterns, relationships, and outliers in the dataset. EDA helps to uncover hidden insights and trends, which can inform further modeling decisions.\n",
    "\t4.\tModeling: Once a deep understanding of the data is achieved, machine learning or statistical models are applied to make predictions, classifications, or decisions. Depending on the problem, different techniques such as regression, classification, clustering, or neural networks may be used. Model selection, training, validation, and tuning are critical steps that require expertise to achieve high performance.\n",
    "\t5.\tDeployment and Monitoring: A data science project does not end with building a model. The final step involves deploying the model in a real-world environment where it can generate value for the business. This might involve integrating the model into applications or systems. Continuous monitoring is required to ensure that the model’s performance remains accurate over time, and regular updates may be needed as new data becomes available.\n",
    "'''\n",
    "\n",
    "\n",
    "model = 'sshleifer/distilbart-cnn-12-6'\n",
    "summarizer = pipeline(task='summarization', model=model)\n",
    "\n",
    "summary_text = summarizer(text)\n",
    "\n",
    "print(summary_text[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc546a-94b7-494f-b3a3-d4be9ca5a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(task='summarization', model=model, min_length=10, max_length=50) # length in words\n",
    "\n",
    "summary_text = summarizer(text)\n",
    "\n",
    "print(summary_text[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb645441-395b-49f3-a50c-1e70c35d19e0",
   "metadata": {},
   "source": [
    "# Images\n",
    "\n",
    "Preprocessing images is and important step since: \n",
    "- Models may have expectations about size, colors... of the image\n",
    "- Maintaens consistency\n",
    "- Can target specific parts of the images\n",
    "\n",
    "## Cropping \n",
    "\n",
    "Removing unwanted parts \n",
    "\n",
    "## Resizing  \n",
    "\n",
    "Change the size of the image. May impact the resolution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca7a34-60e7-4642-9243-b5b0913b1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import image_transforms \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "original_image = Image.open('images/dragon-ball-z.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e9eba-32e8-4abd-b0ca-df3acef1d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "image_array = np.array(original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009f3d0-39ae-49c5-b613-d49bc52561b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4994dec-3781-4568-b837-81527a54ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = image_transforms.center_crop(\n",
    "    image=image_array, \n",
    "    size=(50, 50)\n",
    ")\n",
    "\n",
    "cropped_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724d80c-9f2e-4743-9980-7c50b703eba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T13:15:47.786899Z",
     "iopub.status.busy": "2024-10-14T13:15:47.785704Z",
     "iopub.status.idle": "2024-10-14T13:15:47.795280Z",
     "shell.execute_reply": "2024-10-14T13:15:47.793866Z",
     "shell.execute_reply.started": "2024-10-14T13:15:47.786848Z"
    }
   },
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ef3b9-7815-480c-a5a2-263b52489041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task= 'image-classification',\n",
    "                     model='google/vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4984459-887b-4eb1-a218-8a5931b731cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier('images/free-photo-of-a-boat-is-docked-in-front-of-a-row-of-buildings.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b0369-f3a4-4ef5-bb6e-dd5387d2d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier('images/free-photo-of-a-boat-is-docked-in-front-of-a-row-of-buildings.jpeg', top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc13792-4fad-4e36-b892-6f4bfdd14cac",
   "metadata": {},
   "source": [
    "# Question answering and multi-modal tasks\n",
    "\n",
    "Answering the questions about content of a document \n",
    "\n",
    "Document is a text based images \n",
    "\n",
    "Question is specific to the document \n",
    "\n",
    "Answer can be direct quote or paraphrased response \n",
    "\n",
    "Visual question and answering is similar buy using image or video as input.\n",
    "\n",
    "The pipeline require the document and the question. \n",
    "\n",
    "Use cases are information retrieval in customer support, legal compliance...\n",
    "\n",
    "Multi modal tasks involve more than one type of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ceec6a-1437-481a-a885-225bc8dd8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "dqa = pipeline(task = 'document-question-answering', \n",
    "              model='naver-clova-ix/donut-base-finetuned-docvqa')\n",
    "document_image='images/hq720.jpg'\n",
    "question_text='What is this memo about'\n",
    "\n",
    "results = dqa(document_image, question_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f96ccc-905a-4063-b448-50eba3f11bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ab227-2c4a-4490-8088-3867f757427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "vqa = pipeline(task='visual-question-answering', \n",
    "              model='dandelin/vilt-b32-finetuned-vqa'\n",
    "              )\n",
    "\n",
    "results = vqa(image='images/free-photo-of-a-boat-is-docked-in-front-of-a-row-of-buildings.jpeg',\n",
    "             question='whats the color of the boat')\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d26cb3-3111-4e54-af96-0bfae69c1da3",
   "metadata": {},
   "source": [
    "# Audio Classification\n",
    "\n",
    "Sampling is a very important step that allows to standardize the signals. All the observations in our dataset have to have the same sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee1834-cbd5-4ce5-bd24-f64da5b72a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "# songs = songs.cast_column('audio', Audio(sampling_rate=16_000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83739c7-9f63-4b56-91a7-25465abcd164",
   "metadata": {},
   "source": [
    "The **librosa** library contains tools to get the duration of audio files among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c06de-d04d-4c14-9df3-2c740eee97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1edd8cd-166e-429e-a459-a4851fe446f5",
   "metadata": {},
   "source": [
    "# Audio Classification\n",
    "\n",
    "Process of qssigning one or more lables to audio clips based on its content. Language identification, environmental sounds, speaker identification...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95c9bc-3f39-4023-a0ec-0182f149288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Convert .m4a to .wav\n",
    "def convert_m4a_to_wav(input_file, output_file):\n",
    "    audio = AudioSegment.from_file(input_file, format=\"m4a\")\n",
    "    audio.export(output_file, format=\"wav\")\n",
    "\n",
    "input_m4a = \"audios/Sin título.m4a\"\n",
    "output_wav = \"audios/output_file.wav\"\n",
    "convert_m4a_to_wav(input_m4a, output_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c45f08-026c-48ed-9157-de73804d9a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task='audio-classification', \n",
    "                     model='superb/wav2vec2-base-superb-ks')\n",
    "\n",
    "results = classifier(output_wav)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d810d6ce-d107-45ed-8851-a71b75632845",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = pipeline(\"feature-extraction\", model=\"facebook/wav2vec2-base-960h\")\n",
    "features = feature_extractor(output_wav)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cc5c84-993a-45b4-8373-3bba706e64b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T15:35:13.621189Z",
     "iopub.status.busy": "2024-10-14T15:35:13.620355Z",
     "iopub.status.idle": "2024-10-14T15:35:13.634432Z",
     "shell.execute_reply": "2024-10-14T15:35:13.627721Z",
     "shell.execute_reply.started": "2024-10-14T15:35:13.621133Z"
    }
   },
   "source": [
    "# Automatic Speech Recognition\n",
    "\n",
    "'facebook/wave2vec2-base-960h' and 'openai/whisper-base' are two good models for ASR \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8e858-fc00-4fea-810a-c1ea5ad66d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = pipeline(task='automatic-speech-recognition', \n",
    "                      model='facebook/wav2vec2-base-960h')\n",
    "\n",
    "transcriber(output_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31684a6a-f865-405e-a994-67e1df1a3041",
   "metadata": {},
   "source": [
    "A common wat to evaluate ASR systems is the Word Error Rate (WER), based on the levenshtein Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9314902e-e93d-4bdb-b5e5-a9ba9fc2224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load \n",
    "\n",
    "wer = load('wer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e233c1-eaf6-4869-b9b9-9d0ddfe75b96",
   "metadata": {},
   "source": [
    "# Fine Tuning \n",
    "\n",
    "Adjusting a pretrained model for a specific task or dataset. A pretrained model is an algorithm developed on extensive data to perform a task. \n",
    "\n",
    "The two main reasons for fine tuning are: \n",
    "- Learn new task or domain\n",
    "- Reduced time and computation\n",
    "\n",
    "How to fine tune a model? \n",
    "- Identify the model: \n",
    "- Prepare the data\n",
    "- Build trainer\n",
    "- Train the model\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d0e55f-bcd4-45df-b2fe-f773ca3c773b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T16:25:15.024730Z",
     "iopub.status.busy": "2024-10-14T16:25:15.023868Z",
     "iopub.status.idle": "2024-10-14T16:25:15.035883Z",
     "shell.execute_reply": "2024-10-14T16:25:15.034289Z",
     "shell.execute_reply.started": "2024-10-14T16:25:15.024664Z"
    }
   },
   "source": [
    "Setup the dataset object!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5f2f8-a96d-45ce-979d-495ec3b129eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Use tokenizer on text\n",
    "dataset = dataset.map(lambda row: tokenizer(row[\"text\"], padding=True, max_length=512, truncation=True), keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1fead9-bc7a-4cb6-88d4-060f70cd2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create the classifier\n",
    "classifier = pipeline(task=\"sentiment-analysis\", model=\"./fine_tuned_model\")\n",
    "\n",
    "# Classify the text\n",
    "results = classifier(text=text_example)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2fe856-79de-43cf-bf55-78ea6936c849",
   "metadata": {},
   "source": [
    "# Text Generation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b68f7b-7ed0-4253-bca9-e7ee6acbf89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Set model name\n",
    "model_name = \"gpt2\"\n",
    "\n",
    "# Get the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"Start scratching your head because\"\n",
    "\n",
    "# Tokenize the input\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the text output\n",
    "output = model.generate(input_ids, num_return_sequences=1)\n",
    "\n",
    "# Decode the output\n",
    "generated_text = tokenizer.decode(output[0])\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832a82f-d9f5-4fd8-ac39-ce4aed6fed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from PIL import Image\n",
    "\n",
    "original_image = Image.open('images/free-photo-of-a-boat-is-docked-in-front-of-a-row-of-buildings.jpeg')\n",
    "\n",
    "# Get the processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/git-base-coco\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/git-base-coco\")\n",
    "\n",
    "# Process the image\n",
    "pixels = processor(images=original_image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "# Generate the ids\n",
    "output = model.generate(pixel_values=pixels)\n",
    "\n",
    "# Decode the output\n",
    "caption = processor.batch_decode(output)\n",
    "\n",
    "print(caption[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8760f-1b67-4472-89a0-8ad652d200fb",
   "metadata": {},
   "source": [
    "# Embeddings \n",
    "\n",
    "Embeddings are numerical representations of . Each embeddings has n-dimensions.\n",
    "\n",
    "Embeddings are useful in recommender sysetms, searches and fraud detection for instance. \n",
    "\n",
    "Benefits: \n",
    "- semantic understanding\n",
    "- embeddings can be used as features\n",
    "- improved generalization\n",
    "\n",
    "Challenges: \n",
    "- Huge amount of data to create them\n",
    "- Hard to interpret\n",
    "- Inherit bias from the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be337c-cc09-463b-b4d1-ae7886dbbead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = 'all-MiniLM-L6-v2'\n",
    "embedder = SentenceTransformer(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ae54a2-c783-4a31-bcd6-b4e437890d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformers\n",
    "SentenceTransformers(\"sentence-transformers/paraphrase-albert-small-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820bc264-a1d8-40de-a8b7-e30dab2dd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'What are embeddings?' \n",
    "\n",
    "embedding = embedder.encode([sentence]) \n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589fccf4-e05e-4cf2-af9d-5e65700800a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the first embedding model\n",
    "embedder1 = SentenceTransformers(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Embed the sentence\n",
    "embedding1 = embedder1.encode([sentence])\n",
    "\n",
    "# Create and use second embedding model\n",
    "embedder2 = SentenceTransformer(\"sentence-transformers/paraphrase-albert-small-v2\")\n",
    "embedding2 = embedder2.encode([sentence])\n",
    " \n",
    "# Compare the shapes\n",
    "print(embedding1.shape == embedding2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d520272-1b3b-48b5-b218-ab7de3ca2bdd",
   "metadata": {},
   "source": [
    "# Semantic Search\n",
    "\n",
    "Type of search technology that tries to improve accuracy by understanding the intent and context behind the query.\n",
    "\n",
    "It tries to find content matching the meaning, and not word matches.\n",
    "\n",
    "Cosine similarity can be applied on embeddings to perform searches.\n",
    "\n",
    "When searching with cosine, we embedd the question and find close documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b484a5c3-737d-447d-87a4-5dd7ed286ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformers\n",
    "\n",
    "embedder1 = SentenceTransformers(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bd92f-7471-4adf-9031-52c6862d63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc895e0-7718-4aa3-be47-f32f0d4773a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = util.semantic_search(query_embedding, document_embeddings, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c054fdc9-e74b-4deb-8047-d0bed41209d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I need a desktop book reader for Mac\"\n",
    "\n",
    "# Generate embeddings\n",
    "query_embedding = embedder.encode([query])[0]\n",
    "\n",
    "# Compare embeddings\n",
    "hits = util.semantic_search(query_embedding, sentence_embeddings, top_k=2)\n",
    "\n",
    "# Print the top results\n",
    "for hit in hits[0]:\n",
    "    print(sentences[hit[\"corpus_id\"]], \"(Score: {:.4f})\".format(hit[\"score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3a1b2-b938-4dfe-84ae-980a095311d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
