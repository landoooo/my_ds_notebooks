{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b15884-b24e-42e1-b491-8c83db39c2b1",
   "metadata": {},
   "source": [
    "# Recipe Site Traffic\n",
    "\n",
    "https://s3.amazonaws.com/talent-assets.datacamp.com/Practical+-+DSP+-+Recipe+Site+Traffic+-+2212.pdf\n",
    "\n",
    "| Column Name   | Details                                                                                                        |\n",
    "|---------------|----------------------------------------------------------------------------------------------------------------|\n",
    "| recipe        | Numeric, unique identifier of recipe                                                                           |\n",
    "| calories      | Numeric, number of calories                                                                                    |\n",
    "| carbohydrate  | Numeric, amount of carbohydrates in grams                                                                      |\n",
    "| sugar         | Numeric, amount of sugar in grams                                                                              |\n",
    "| protein       | Numeric, amount of protein in grams                                                                            |\n",
    "| category      | Character, type of recipe. Recipes are listed in one of ten possible groupings ('Lunch/Snacks', 'Beverages', 'Potato', 'Vegetable', 'Meat', 'Chicken', 'Pork', 'Dessert', 'Breakfast', 'One Dish Meal') |\n",
    "| servings      | Numeric, number of servings for the recipe                                                                     |\n",
    "| high_traffic  | Character, if the traffic to the site was high when this recipe was shown, this is marked with “High”          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3672e6f2-3e91-4ca0-b182-b729f45163f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "df = pd.read_csv('recipe_site_traffic_2212.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1676453-8fdb-4cee-ba7f-c81ec118deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a2555f-ce6a-4a07-98ea-4aa6280bf213",
   "metadata": {},
   "source": [
    "There are null values in 4 independent variables and in the target. For the target its easy to get rid of the values due to the explanation included in the data dictionary. Lets make it a boolean True when it contains 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3218a3-204f-4e22-9643-afcf973b0a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['high_traffic'] = df['high_traffic']=='High'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4b5c26-d76b-4211-922c-c59797642718",
   "metadata": {},
   "source": [
    "Lets understand a bit better whats going on with the other na's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca856661-fcb7-4852-bc9e-f188f6400e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['calories'].isna()].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3465a1d-9f32-48df-a460-98f6c998943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35de73e-d5ae-46a6-b4bc-0262a2920cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] = df['category'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09642241-3277-44d0-8a69-5e4bd9b44141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['servings'][~pd.to_numeric(df['servings'], errors='coerce').notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3708f992-a08b-4408-b832-ec59829c6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['snack'] = df['servings'].str.contains('as a snack')\n",
    "df['servings'] = df['servings'].str.replace(' as a snack', '')\n",
    "df['servings'] = df['servings'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef6e3fa-4e1d-4a92-bb8c-4fbb200fb7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, hue='category', y='calories')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a63247-b02b-42b7-a9cd-e70fe19958ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, hue='category', y='carbohydrate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917d355-9b27-4c97-85ca-2e76bf680dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, hue='category', y='sugar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8afc11-4cf9-41ac-a785-0e873dd288c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, hue='category', y='protein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e86bc5-4992-450e-8ef7-3cc10773b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['sugar'].isna())['high_traffic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5053fc-8ba2-473a-bf43-adbc5bd6bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for missing_col in ['calories', 'sugar', 'protein', 'carbohydrate']:\n",
    "    df[missing_col] = df[missing_col].fillna(df.groupby(['category', 'servings'])[missing_col].transform('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68db737-d421-476e-be38-910c39d5e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c941cf-a702-4e56-8cf8-e742377f837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['calories', 'carbohydrate', 'sugar', 'protein']:\n",
    "    df[col] = np.log1p(df[col])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a5cbd-4dee-4abb-9d42-68303ab82d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() \n",
    "\n",
    "numeric_cols = ['calories', 'sugar', 'protein', 'carbohydrate', 'servings']\n",
    "numeric_cols_extra = []\n",
    "\n",
    "for numeric_col in numeric_cols: \n",
    "    for numeric_col_2 in numeric_cols: \n",
    "        column_extra_name = numeric_col+'_'+numeric_col_2\n",
    "        df[numeric_col+'_'+numeric_col_2] = df[numeric_col]*df[numeric_col_2]\n",
    "        numeric_cols_extra.append(column_extra_name)\n",
    "\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "df[numeric_cols_extra] = scaler.fit_transform(df[numeric_cols_extra])\n",
    "\n",
    "df = pd.get_dummies(df, columns=['category'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c8ba1-4bb7-46dd-aa23-2b4533843d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb9e23b-8add-4cd1-9d98-28985104afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "X = df.drop('high_traffic', axis=1)\n",
    "y = df['high_traffic'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = [LogisticRegression(penalty='l2', C=0.6, solver='liblinear'), \n",
    "          LogisticRegression(penalty='l1', C=0.6, solver='saga'), \n",
    "          LogisticRegression(),\n",
    "          RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=5 ),\n",
    "          RandomForestClassifier(n_estimators=500, max_depth=15, min_samples_split=3 )\n",
    "         ]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(model)\n",
    "    print(model.score(X_train, y_train))\n",
    "    print(accuracy_score(y_pred, y_test))\n",
    "    print(confusion_matrix(y_pred, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786ff66-009e-4401-acfb-ad1f87fbba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the models and their parameter grids\n",
    "models = {\n",
    "    'logistic_regression': LogisticRegression(solver='liblinear', max_iter=200),\n",
    "    'random_forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'logistic_regression': {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],       # Regularization strength\n",
    "        'penalty': ['l1', 'l2'],                   # Regularization type\n",
    "        'class_weight': [None, 'balanced']         # Handles class imbalance\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'n_estimators': [50, 100, 200, 300],       # Number of trees in the forest\n",
    "        'max_depth': [None, 10, 20, 30],           # Maximum depth of each tree\n",
    "        'min_samples_split': [2, 5, 10],           # Minimum number of samples required to split a node\n",
    "        'min_samples_leaf': [1, 2, 4],             # Minimum number of samples required to be at a leaf node\n",
    "        'max_features': ['sqrt', 'log2', None],    # Number of features to consider when looking for the best split\n",
    "        'bootstrap': [True, False],                # Whether to use bootstrap sampling\n",
    "        'class_weight': [None, 'balanced']         # Handles class imbalance\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dictionary to store the best models and scores\n",
    "results = {}\n",
    "\n",
    "# Perform grid search for each model\n",
    "for model_name, model in models.items():\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid=param_grids[model_name],\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Store the best parameters and scores\n",
    "    results[model_name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_estimator': grid_search.best_estimator_\n",
    "    }\n",
    "    \n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    results[model_name]['test_accuracy'] = test_accuracy\n",
    "\n",
    "# Display results\n",
    "for model_name, result in results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\" Best Parameters: {result['best_params']}\")\n",
    "    print(f\" Best Cross-Validation Score: {result['best_score']}\")\n",
    "    print(f\" Test Accuracy: {result['test_accuracy']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615f507-f2db-4e88-8ca1-564bece35a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
