{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b529b6-5b76-424e-b09c-8917c8c5f4b2",
   "metadata": {},
   "source": [
    "# Recipe Site Traffic 2\n",
    "\n",
    "## 1. Define the Problem and Project Objectives\n",
    "Tasty Bytes has today a manual mechanism to select the recipe to be displayed on the home page. Picking a 'popular' recipe has a positive impact of up to 40% in traffic in the rest of the website, leading to more subscriptions and therefore, more revenue.\n",
    "\n",
    "The goal of this notebook is to perform an analysis on: \n",
    "- how to predict which recipes will be popular 80% of the time (accuracy)\n",
    "- and minimize the chance of showing unpopular recipes (precision)\n",
    "\n",
    "The provided dataset to perform this analysis is available in the file recipe_site_traffic_2212.csv and contains the following fields: \n",
    "\n",
    "| Column Name   | Details                                                                                                       |\n",
    "|---------------|---------------------------------------------------------------------------------------------------------------|\n",
    "| recipe        | Numeric, unique identifier of recipe                                                                          |\n",
    "| calories      | Numeric, number of calories                                                                                   |\n",
    "| carbohydrate  | Numeric, amount of carbohydrates in grams                                                                     |\n",
    "| sugar         | Numeric, amount of sugar in grams                                                                             |\n",
    "| protein       | Numeric, amount of protein in grams                                                                           |\n",
    "| category      | Character, type of recipe. Recipes are listed in one of ten possible groupings ('Lunch/Snacks', 'Beverages', 'Potato', 'Vegetable', 'Meat', 'Chicken', 'Pork', '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ee995-f59c-4e90-b081-2ba8be4d48f0",
   "metadata": {},
   "source": [
    "## 2. Data Collection and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c674f39-c39d-4d26-8174-ce7ef6a3acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6021ac-08df-4491-866c-fcb5c09ef64b",
   "metadata": {},
   "source": [
    "Lets read the data and have a first idea about its quality regarding types and null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f92f4-3e81-4922-b60f-af7a8ed566e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('recipe_site_traffic_2212.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005508f-7121-4151-b2a6-8b629b51c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc98e26-c1f0-49a4-ba58-ae08b9202d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a52ded-de7e-455c-96c8-ddeab5af73ac",
   "metadata": {},
   "source": [
    "There are nulls in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd148d8-e393-4035-8333-7a20424cddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9e068-32b1-47e8-8584-cd3d285896e6",
   "metadata": {},
   "source": [
    "- The *servings* feature should be numeric\n",
    "- *high_traffic* can be boolean and has nulls too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a0b6a-6fcf-44d7-83ec-869316208e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recipe'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e235e9-a3f5-41df-8ae4-eb50b5982ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f91b42-90b8-4e6c-86a5-19f9f5f74101",
   "metadata": {},
   "source": [
    "The range of *calories* seems way over the other ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72003ef-1157-4c2c-a099-18b259a9b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['calories'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3888e6b-8587-4e21-ab5a-61289f8bb6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a9f26e-c32b-4ffb-973e-fbf5dd70e4b9",
   "metadata": {},
   "source": [
    "After a first look to the dataset, we can conclude: \n",
    "- We have 947 recipes \n",
    "- We have 6 independent variables and one target (high_traffic)\n",
    "- 4 of the features have 2 null values, all of them corresponding to the same rows. These null values correspond to different 'categories' and serving values\n",
    "- The target variable contains 377 null values that should be encoded as 'False' as estated in the data dictionary provided.\n",
    "- The serving feature, supposed to contain integers, contain 3 faulty entries that must be cleaned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6043e4-fd2f-4b46-a4fd-72f275bc82ed",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning\n",
    "\n",
    "### 3.1. Category type\n",
    "\n",
    "The category feature has been loaded as an 'object'. We can encode it as a category. It will help us save some memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0750637-cec7-49bf-8afb-90236f8641aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601eb187-8f46-47a7-a676-fdb22801b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] = df['category'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64acc316-8c9c-438b-bc60-f9ca550e57f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(data=df, x='category', hue='category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Distribution of categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f75851f-f377-4e49-ad9a-cc22a98e3d83",
   "metadata": {},
   "source": [
    "### 3.2. Servings non numeric\n",
    "\n",
    "Some of the servings are non numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee6ec1b-79bc-42c0-bd72-2a696adaf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['servings'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8e804-82a5-4e7b-a905-bfb16a8c837a",
   "metadata": {},
   "source": [
    "There are 3 weird serving values. Lets clean them up. And lets consider servings as a category rather than a numeric field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b89ea-6dc9-4bc9-820f-2fb88730dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['servings'] = df['servings'].str[0].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2163b0-1e25-41c1-ad51-a70a9f1229b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='servings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add03952-2f92-427d-90e5-7cae6669303c",
   "metadata": {},
   "source": [
    "### 3.3. Null values in Calories, Protein, Carbohydrate and Sugar\n",
    "\n",
    "Since the nature of this issue seems pretty similar, lets group these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567bb37-5f05-486c-a97d-c55ff2309bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df.calories)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811642b7-33cc-4b6e-8bd7-b59f7099dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df.protein)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf14a2-5285-48dc-b414-39cace800351",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df.sugar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6c10e8-0755-47d9-a42e-4935d692babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df.carbohydrate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc9478-04a2-4243-a501-bda8de63c998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T16:16:50.623301Z",
     "iopub.status.busy": "2024-11-03T16:16:50.619239Z",
     "iopub.status.idle": "2024-11-03T16:16:50.634319Z",
     "shell.execute_reply": "2024-11-03T16:16:50.632605Z",
     "shell.execute_reply.started": "2024-11-03T16:16:50.623174Z"
    }
   },
   "source": [
    "The distributions of all these 4 numeric features is highly skewed to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e230c-45b1-4c7f-a9ab-853e68113abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df, hue='category', y='calories', linewidth=0.5)\n",
    "plt.title('Calories distribution by category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2851aa6b-e699-40e2-abf8-4e38b914e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df, hue='category', y='protein', linewidth=0.5)\n",
    "plt.title('Protein distribution by category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3394c56-6d52-4d41-bcdf-d8a39fc43706",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df, hue='category', y='sugar', linewidth=0.5)\n",
    "plt.title('Sugar distribution by category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3eb952-4e7a-4394-9247-369b60d1973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df, hue='category', y='carbohydrate', linewidth=0.5)\n",
    "plt.title('Carbohydrate distribution by category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5737d45-efae-4ae9-a6c9-d4285cd4d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df, hue='servings', y='protein', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a39c14-51c1-4cf3-bff5-03c6cffc265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df, hue='servings', y='sugar', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178702b-7863-4b26-9895-92f6d21559cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df, hue='servings', y='calories', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93ea83-10c3-4b37-aaaf-ca0c1f925918",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df, hue='servings', y='carbohydrate', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793dbd72-0742-44dc-98ed-4c160784fcf4",
   "metadata": {},
   "source": [
    "Lets impute the missing calories, sugar, protein and carbohydrate with the mean for each category. I initially thought about using the servings feature to refine the mean to be imputed, but it seems there is no variation in these columns due to the amout of servings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd9b90-cfe8-4f60-809d-68645a8edadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['sugar', 'calories', 'protein', 'carbohydrate']:\n",
    "    df[column] = df.groupby('category')[column].transform(lambda x: x.fillna(x.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae31097-dc87-4294-bec1-4916c8749499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbac9183-7fbe-4ef0-b4bf-4477260debd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T16:41:09.009345Z",
     "iopub.status.busy": "2024-11-03T16:41:09.009112Z",
     "iopub.status.idle": "2024-11-03T16:41:09.012557Z",
     "shell.execute_reply": "2024-11-03T16:41:09.011873Z",
     "shell.execute_reply.started": "2024-11-03T16:41:09.009330Z"
    }
   },
   "source": [
    "Lets convert the target column into a boolean one, like that we get rid of the null values on this column too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647723d-20af-42d0-9e45-0be141cdcfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['high_traffic'] = np.where(df['high_traffic'] == 'High', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a55f9-f6df-4c12-aae1-005aaf19fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['high_traffic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9aed0e-feb7-40a6-ad4a-6c584235d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='high_traffic', hue='high_traffic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7254ec5f-3990-496f-a097-12812ab9a33f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T15:59:40.245153Z",
     "iopub.status.busy": "2024-11-03T15:59:40.244299Z",
     "iopub.status.idle": "2024-11-03T15:59:40.263000Z",
     "shell.execute_reply": "2024-11-03T15:59:40.261163Z",
     "shell.execute_reply.started": "2024-11-03T15:59:40.245107Z"
    }
   },
   "source": [
    "If we randomly chose a recipe, it would be 60% of the times a high traffic one. This could be our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2cddd5-c40f-4736-8bf4-a80c3af5ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5fdc7e-fd77-45ff-9c72-29803733ac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d252a-631c-4e51-9d35-74aa57f1c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e83763-4ae0-46b0-906e-27d62fc6f0f9",
   "metadata": {},
   "source": [
    "The data seems clean now after having imputed missing values, fix wrong typing and clean messy servings. We are now ready to prepare the data to train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927007a-8014-4b01-9da6-a9caf914558f",
   "metadata": {},
   "source": [
    "Since the protein, sugar, carbo and calories columns were highly skewed we will apply a log transformation to normalize their distributions. This will normalize the features, reduce their ranges and the outliers, making the distributions more symmetric too. This should have a positive impact in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae5582-f2c3-4edc-b316-5f94af57b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_calories'] = np.log(df['calories'])\n",
    "sns.kdeplot(data=df, x='calories')\n",
    "plt.show()\n",
    "sns.kdeplot(data=df, x='log_calories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924aac5-118a-45e7-8b04-a3f9e0bf6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_protein'] = np.log1p(df['protein']) # protein contains 0's\n",
    "sns.kdeplot(data=df, x='protein')\n",
    "plt.show()\n",
    "sns.kdeplot(data=df, x='log_protein')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e2cf81-469d-4052-9c9a-1a8751b3a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_sugar'] = np.log1p(df['sugar'])\n",
    "sns.kdeplot(data=df, x='sugar')\n",
    "plt.show()\n",
    "sns.kdeplot(data=df, x='log_sugar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696f50a-30be-47c4-9245-0a90669e72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_carbohydrate'] = np.log1p(df['carbohydrate'])\n",
    "sns.kdeplot(data=df, x='carbohydrate')\n",
    "plt.show()\n",
    "sns.kdeplot(data=df, x='log_carbohydrate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c89be7-b828-4203-b8c8-1057f5d0b048",
   "metadata": {},
   "source": [
    "These new log_* features are more symmetric than the originals.\n",
    "\n",
    "Lets now: \n",
    "- get rid of *recipe* id, useless for training\n",
    "- scale the numeric fields\n",
    "- encode the *category* and *servings* features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3fd06-a315-4f80-9e85-9638824dc10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0576e069-5d15-46b1-9051-401af8328b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['recipe', 'calories', 'sugar', 'protein', 'carbohydrate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af5616-5d59-44dc-b30c-db1451968a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fb7a6-70df-4c87-8b3d-bdbdb8370c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_cols = ['log_calories', 'log_protein', 'log_sugar', 'log_carbohydrate']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139388a9-d1bb-4b85-9333-69df8169cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e0c12-a787-48ea-af33-5fe3bddc6513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c92e1-d9f3-4f22-88ff-f6c4300432c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['category', 'servings'], drop_first=True)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096438d-4e27-4aa0-af01-2bdc9cf740ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_encoded.drop('high_traffic', axis=1)\n",
    "y = df_encoded['high_traffic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb3a9b-a004-4e3d-92b0-825ff3c36cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Initialize models and parameters\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Parameter grids\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs', 'liblinear']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Loop through models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining Model: {model_name}\")\n",
    "    \n",
    "    # For Logistic Regression and Random Forest, perform grid search\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grids[model_name], \n",
    "                               scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "    \n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model from grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_test)}\")\n",
    "    print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc001c9d-9a57-4fa2-8f10-6e6780150bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best parameters from the previous grid search\n",
    "current_best_params = {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "\n",
    "# Create a refined parameter grid for Logistic Regression\n",
    "refined_param_grid = {\n",
    "    'C': [80, 100, 120],  # Narrowing around the best C\n",
    "    'penalty': ['l2'],  # Keeping the same penalty\n",
    "    'solver': ['lbfgs', 'liblinear']  # Retaining the previously successful solvers\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=1000, class_weight={0: 2, 1: 1})\n",
    "\n",
    "# Create grid search for refined Logistic Regression\n",
    "refined_lr_grid_search = GridSearchCV(estimator=logistic_model, param_grid=refined_param_grid, \n",
    "                                       scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "refined_lr_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best refined Logistic Regression model and parameters\n",
    "best_refined_lr_model = refined_lr_grid_search.best_estimator_\n",
    "best_refined_lr_params = refined_lr_grid_search.best_params_\n",
    "\n",
    "# Make predictions on the test set\n",
    "refined_lr_y_pred = best_refined_lr_model.predict(X_test)\n",
    "\n",
    "# Calculate training accuracy\n",
    "train_accuracy = best_refined_lr_model.score(X_train, y_train)\n",
    "\n",
    "# Print results for refined Logistic Regression\n",
    "print(\"Refined Logistic Regression:\")\n",
    "print(f\"Best Parameters: {best_refined_lr_params}\")\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, refined_lr_y_pred):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, refined_lr_y_pred)}\")\n",
    "print(classification_report(y_test, refined_lr_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3a6ab-678e-4744-a24c-0bec4b46abe2",
   "metadata": {},
   "source": [
    "The overall accuracy of this first trained model with the available data is 75% meaning that we can predict a recipe will be popular or not around 3 out of 4 times. On the other hand after playing a bit with the class weights, the precision of this model is around 87%, so when we say a recipe is popular, it will be popular 87 times out of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6c612-5f32-4dff-99d8-2f320d1170a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': best_refined_lr_model.coef_[0]\n",
    "})\n",
    "\n",
    "# Display feature importance sorted by absolute value\n",
    "feature_importance['Importance'] = feature_importance['Importance'].abs()  # Optional: for magnitude sorting\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce566ce-fc72-41fd-911c-082087e95f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(\n",
    "    data=feature_importance,\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Feature Importances (Logistic Regression Coefficients)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ebb74-cc95-45b9-bf10-6b20c19acf79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
