{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351a50b4",
   "metadata": {},
   "source": [
    "# Cohort analysis\n",
    "\n",
    "A descriptive analytics tool. It groups the customers into mutually exclusive cohorts, that are measured over time. Cohort analysis provides deeper insights than the so-called vanity metrics. It helps understanding the high level trends better by providing insights on metrics across both the product and the customer lifecycle.\n",
    "\n",
    "# Types of cohorts\n",
    "## Time cohorts\n",
    "Customers who signed up for a product or service during a particular time frame. Analyzing these cohorts shows the customers bhaviour depending on the time they started using the companys  prdocuts or services. The time can be monthly, quarterly or even daily.\n",
    "\n",
    "## Behaviour cohorts\n",
    "Customers who purchased a product or subscribed to a service in the past. It groups customers by the type of product or service they signed up: those signing for basic level service may have a different behaviour than the ones going premium. Understanding the needs of various cohorts can help a company design customed-made services or products for particular segments.\n",
    "\n",
    "## Size cohorts\n",
    "Refers to the various sizes of customers who purchase companys products or services. This categorization can be based on the amount of spending in some period of  time after acquisition or the product type that the customer spent most of their order amount in some period of time.\n",
    "\n",
    "# Elements of cohort analysis\n",
    "## Pivot table\n",
    "Assigned cohort in rows\n",
    "Cohort index in columns\n",
    "Metrics in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3634f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_counts = pd.read_csv(\"./data/chapter_1/cohort_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b6dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109238f6",
   "metadata": {},
   "source": [
    "There are 332 customers who have made their first transaction in january 2011"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a55b9",
   "metadata": {},
   "source": [
    "# Time Cohorts\n",
    "\n",
    "We will segment customers into acquisition cohorts based on the month they made their first purchase. We will then assign the cohort index to each purchase of the customer. It will represent the number of months since the first transaction.\n",
    "\n",
    "Time based cohorts group customers by the time they completed their first activity. In this lesson, we will group customers into cohorts based on the month of their first purchase. Then we will mark each transaction based on its relative time period since the first purchase. In this example, we will calculate the number of months since the acquisition. In the next step we will calculate metrics like retention or average spend value, and build this heatmap.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69796b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "online = pd.read_csv(\"./data/chapter_1/online.csv\", parse_dates=[\"InvoiceDate\"])\n",
    "online.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b67f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month(x):\n",
    "    return dt.datetime(x.year, x.month, 1)\n",
    "\n",
    "online[\"InvoiceMonth\"] = online[\"InvoiceDate\"].apply(get_month)\n",
    "online[\"CohortMonth\"] = online.groupby(\"CustomerID\")[\"InvoiceMonth\"].transform(\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dfd039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_int(df, column):\n",
    "    year = df[column].dt.year\n",
    "    month = df[column].dt.month\n",
    "    day = df[column].dt.day\n",
    "    return year, month, day\n",
    "\n",
    "invoice_year, invoice_month, _ = get_date_int(online, \"InvoiceMonth\")\n",
    "cohort_year, cohort_month, _ = get_date_int(online, \"CohortMonth\")\n",
    "\n",
    "years_diff = invoice_year - cohort_year\n",
    "months_diff = invoice_month - cohort_month\n",
    "online[\"CohortIndex\"] = years_diff * 12 + months_diff + 1\n",
    "online.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfecf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_data = online.groupby([\"CohortMonth\", \"CohortIndex\"])[\"CustomerID\"].nunique().reset_index()\n",
    "\n",
    "cohort_counts = cohort_data.pivot(index=\"CohortMonth\", columns=\"CohortIndex\", values=\"CustomerID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c848226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae620d4a",
   "metadata": {},
   "source": [
    "The first column indicates how many customers are initially on each cohort (100% for all cohorts). Then, how many customers were still actives in the following months.\n",
    "\n",
    "# Metrics\n",
    "\n",
    "## Retention Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4068fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_sizes= cohort_counts.iloc[:, 0]\n",
    "retention = cohort_counts.divide(cohort_sizes, axis=0).round(3)*100\n",
    "retention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15292c",
   "metadata": {},
   "source": [
    "## Other Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_data = online.groupby([\"CohortMonth\", \"CohortIndex\"])[\"Quantity\"].mean()\n",
    "cohort_data = cohort_data.reset_index()\n",
    "average_quantity = cohort_data.pivot(index=\"CohortMonth\", columns=\"CohortIndex\", values=\"Quantity\")\n",
    "\n",
    "average_quantity = average_quantity.round(2)\n",
    "average_quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b03f0e",
   "metadata": {},
   "source": [
    "# Visualizing Cohort Analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ad3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Cohort Analysis: Retention Rates\")\n",
    "sns.heatmap(\n",
    "    retention,\n",
    "    annot=True,\n",
    "    fmt=\".0f\",\n",
    "    cmap=\"Blues\",\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"white\",\n",
    "    cbar_kws={\"label\": \"Retention Rate (%)\"},\n",
    ")\n",
    "plt.xlabel(\"Cohort Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b095fd3c",
   "metadata": {},
   "source": [
    "# Recency, Frequency, Monetary (RFM) segmentation\n",
    "We asign customers to segments depending on their recency, frequency and monetary values.\n",
    "\n",
    "## Recency\n",
    "How recent is each customer last purchase. The lower it is, the better. Every company wants their customers to be recent and active.\n",
    "\n",
    "## Frequency\n",
    "How many purchases the customer has done in the last 12 months. The period can change depending on the product lifecycle, etc.\n",
    "\n",
    "## Monetary Value\n",
    "How much has the customer spent in the last 12 months. The period can change depending on the product lifecycle, etc.\n",
    "\n",
    "Once we calculate these values we can group them into categories like high, medium or low, using percentiles, pareto 80/20 split or custom splits based on business knowledge.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min: {}, Max: {}'.format(online[\"InvoiceDate\"].min(), online[\"InvoiceDate\"].max()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94711e",
   "metadata": {},
   "source": [
    "Lets set a hypothetical snapshot_day as if we were doing the analysis recently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_day = max(online.InvoiceDate) + dt.timedelta(days=1)\n",
    "snapshot_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd631d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "online[\"TotalSum\"] = online[\"Quantity\"] * online[\"UnitPrice\"]\n",
    "\n",
    "datamart = online.groupby(['CustomerID']).agg({\n",
    "    'InvoiceDate': lambda x: (snapshot_day - x.max()).days,\n",
    "    'InvoiceNo': 'count',\n",
    "    'TotalSum': 'sum'\n",
    "})\n",
    "\n",
    "datamart.rename(columns={\n",
    "    'InvoiceDate': 'Recency',\n",
    "    'InvoiceNo': 'Frequency',\n",
    "    'TotalSum': 'MonetaryValue'\n",
    "}, inplace=True)\n",
    "datamart = datamart.reset_index()\n",
    "datamart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61889a2",
   "metadata": {},
   "source": [
    "Once calculated the Recenccy, Frequency and Monetary Value for each customer we can group these customers into 4 segments, depending on their RFM value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d86f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create the labels for the recency, frequency and monetary value\n",
    "# Recency labels\n",
    "# These labels are sorted in descending order since we want to assign the highest value to the most recent customers\n",
    "r_labels = range(4, 0, -1)\n",
    "r_quartiles = pd.qcut(datamart['Recency'], 4, labels=r_labels)\n",
    "datamart['R'] = r_quartiles\n",
    "\n",
    "# Frequency labels\n",
    "# These labels are sorted in ascending order since we want to assign the highest value to the most frequent customers\n",
    "f_labels = range(1, 5)\n",
    "f_quartiles = pd.qcut(datamart['Frequency'], 4, labels=f_labels)\n",
    "datamart['F'] = f_quartiles\n",
    "\n",
    "# Monetary labels\n",
    "# These labels are sorted in ascending order since we want to assign the highest value to the most valuable customers\n",
    "m_labels = range(1, 5)\n",
    "m_quartiles = pd.qcut(datamart['MonetaryValue'], 4, labels=m_labels)\n",
    "datamart['M'] = m_quartiles\n",
    "\n",
    "datamart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277aa7c0",
   "metadata": {},
   "source": [
    "Its time now to create the RFM segment (contactenation of the RFM quartile values) and the RFM score (sum of those values)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4175522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart['RFM_Segment'] = datamart.R.astype(str) + datamart.F.astype(str) + datamart.M.astype(str)\n",
    "datamart['RFM_Score'] = datamart[['R', 'F', 'M']].sum(axis=1)\n",
    "datamart.sort_values('RFM_Score', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d531a",
   "metadata": {},
   "source": [
    "Lets check the size of the different segments. Its always a best practice to do so.\n",
    "The RFM_Segment will allow us to directly select 'similar' customers by using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c1060",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart.groupby('RFM_Segment').size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart[datamart['RFM_Segment'] == '111'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d516b23",
   "metadata": {},
   "source": [
    "## Summary metrics per RFM score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46755cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart.groupby('RFM_Score').agg({\n",
    "    \"Recency\": 'mean',\n",
    "    \"Frequency\": 'mean',\n",
    "    \"MonetaryValue\": 'mean',\n",
    "    \"RFM_Score\": 'count'\n",
    "}).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart[\"RFM_Segment\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47d21b",
   "metadata": {},
   "source": [
    "This segmentation is useful but still confusing. In order to improve usability we can group again these segments into named ones, like Gold, Silver and Bronze.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_me(df):\n",
    "    if df[\"RFM_Score\"] >= 9:\n",
    "        return \"Gold\"\n",
    "    elif df[\"RFM_Score\"] >= 5 and df[\"RFM_Score\"] < 9:\n",
    "        return \"Silver\"\n",
    "    else:\n",
    "        return \"Bronze\"\n",
    "\n",
    "datamart[\"General_Segment\"] = datamart.apply(segment_me, axis=1)\n",
    "datamart.groupby(\"General_Segment\").agg({\n",
    "    \"Recency\": \"mean\",\n",
    "    \"Frequency\": \"mean\",\n",
    "    \"MonetaryValue\": \"mean\",\n",
    "    \"RFM_Score\": \"count\",\n",
    "}).round(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19606cb3",
   "metadata": {},
   "source": [
    "In real life,  this process could require several iterations to find the best segmentation for your business.\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "## K means clustering\n",
    "Why K means\n",
    "- One of the most popular unsupervised learning method\n",
    "- Pretty fast\n",
    "- Works well as long as the assumptions about the data are correct:\n",
    "    - Symmetric distribution of variables (not skewed)\n",
    "    > When facing skewed variables, logarithmic transformations can help making the distribution more symmetrical. It works on positive values only.\n",
    "    - Variables have the same average values\n",
    "    - Variables have the same variance\n",
    "    > RFM data doest not have same average values nor same variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1388b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart[['Recency', 'Frequency', 'MonetaryValue']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1997c1",
   "metadata": {},
   "source": [
    "The best way to identify skewed variables is to plot their distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6063514",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(datamart['Recency'], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(datamart[\"Frequency\"], kde=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f877237",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_log = np.log(datamart['Frequency'])\n",
    "sns.histplot(frequency_log, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a8c13",
   "metadata": {},
   "source": [
    "## Centering and Scaling variables\n",
    "\n",
    "### Assessing the issue\n",
    "A simple .describe() of the variables can help us identifying the pressence of the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substracting the mean from every value will center the data around 0\n",
    "datamart_rfm = datamart[['Recency', 'Frequency', 'MonetaryValue']]\n",
    "datamart_centered = datamart_rfm - datamart_rfm.mean()\n",
    "datamart_centered.describe().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing by the standard deviation will scale the data to a standard deviation of 1\n",
    "datamart_scaled = datamart_rfm/datamart_rfm.std()\n",
    "datamart_scaled.describe().round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7571d6e",
   "metadata": {},
   "source": [
    "These operations can be done manually or using the sklearn StandardScaler class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788dec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "datamart_sklearn_scaled = scaler.fit_transform(datamart_rfm)\n",
    "print('mean: ', datamart_sklearn_scaled.mean(axis=0).round(2))\n",
    "print('std: ', datamart_sklearn_scaled.std(axis=0).round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22cf282",
   "metadata": {},
   "source": [
    "The order in which the operations has to be performed is important, since some operations cannot be applied on negative values, and some other generate negative values for instance:\n",
    "\n",
    "1.- Unskew the data (log transformation)\n",
    "2.- Standardize the values\n",
    "3.- Scale the to the same standard deviation\n",
    "4.- Store as a separate array to be used for clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d1a0cd",
   "metadata": {},
   "source": [
    "To find the numbers of clusters you can use:\n",
    "- elbow criteria\n",
    "- silhouette coefficient\n",
    "- Experimentation and interpretation\n",
    "\n",
    "Its important that the clusters makes sense at business level and that are actionable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=1)\n",
    "kmeans.fit(datamart_sklearn_scaled)\n",
    "cluster_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bdc036",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart_rfm_k2 = datamart_rfm.assign(Cluster = cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart_rfm_k2.groupby('Cluster').agg({\n",
    "    'Recency': 'mean',\n",
    "    'Frequency': 'mean',\n",
    "    'MonetaryValue': ['mean', 'count']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a7e26",
   "metadata": {},
   "source": [
    "### Elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e623c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse={}\n",
    "\n",
    "for k in range(1, 15):\n",
    "    # Initialize KMeans with k clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "\n",
    "    # Fit KMeans on the normalized dataset\n",
    "    kmeans.fit(datamart_sklearn_scaled)\n",
    "\n",
    "    # Assign sum of squared distances to k element of dictionary\n",
    "    sse[k] = kmeans.inertia_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the plot title \"The Elbow Method\"\n",
    "plt.title(\"The Elbow Method\")\n",
    "\n",
    "# Add X-axis label \"k\"\n",
    "plt.xlabel(\"k\")\n",
    "\n",
    "# Add Y-axis label \"SSE\"\n",
    "plt.ylabel(\"SSE\")\n",
    "\n",
    "# Plot SSE values for each key in the dictionary\n",
    "sns.pointplot(x=list(sse.keys()), y=list(sse.values()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2aa3c6",
   "metadata": {},
   "source": [
    "FALTA....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac682e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BaseML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
