{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc61438f-c939-4adb-9feb-f32b41be70e8",
   "metadata": {},
   "source": [
    "![bookstore](bookstore.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405dc77e-dfb4-44c5-a686-33ed3e845da1",
   "metadata": {},
   "source": [
    "Identifying popular products is incredibly important for e-commerce companies! Popular products generate more revenue and, therefore, play a key role in stock control.\n",
    "\n",
    "You've been asked to support an online bookstore by building a model to predict whether a book will be popular or not. They've supplied you with an extensive dataset containing information about all books they've sold, including:\n",
    "\n",
    "* `price`\n",
    "* `popularity` (target variable)\n",
    "* `review/summary`\n",
    "* `review/text`\n",
    "* `review/helpfulness`\n",
    "* `authors`\n",
    "* `categories`\n",
    "\n",
    "You'll need to build a model that predicts whether a book will be rated as popular or not.\n",
    "\n",
    "They have high expectations of you, so have set a target of at least 70% accuracy! You are free to use as many features as you like, and will need to engineer new features to achieve this level of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8010c2d-a710-4900-931d-96cc39499b25",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 307,
    "lastExecutedAt": 1730551338483,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import some required packages\nimport pandas as pd\n\n# Read in the dataset\nbooks = pd.read_csv(\"data/books.csv\")\n\n# Preview the first five rows\nbooks.head()",
    "outputsMetadata": {
     "0": {
      "height": 235,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import some required packages\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the dataset\n",
    "original = pd.read_csv(\"books.csv\")\n",
    "\n",
    "# Preview the first five rows\n",
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ca34a-d8c9-4354-ba84-7ecd914d1952",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1730551338531,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "books.info()",
    "outputsMetadata": {
     "0": {
      "height": 353,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9397d4e-be80-452f-9cfe-11f2e5802d3b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1730551338578,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "books.describe()",
    "outputsMetadata": {
     "0": {
      "height": 306,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "original.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa3dd6a-590a-4df2-bb8f-8f9286e8fc44",
   "metadata": {},
   "source": [
    "The dataset seems to be a book review dataset instead of a book dataset. The same book (based on its title, price, authors, categories, and description) can appear multiple times. As many as different reviews it's got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b6a2d-8bf3-4cba-8b55-4ccaa3cbe538",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1730551338630,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "books_df = books[['title', 'price', 'authors', 'categories', 'description', 'popularity']]\nbooks_df.duplicated().sum()"
   },
   "outputs": [],
   "source": [
    "books_df = original[['title', 'price', 'authors', 'categories', 'description', 'popularity']]\n",
    "books_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df674f34-3577-450a-a627-2a3c7c0a309e",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 110,
    "lastExecutedAt": 1730551338740,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "targets = books[['title', 'popularity']]\ntargets = targets.pivot_table(columns='popularity', index='title', aggfunc='size', fill_value=0)\ntargets['pop_diff'] = targets['Popular'] - targets['Unpopular']\ntargets['pop'] = targets['pop_diff']>0\ntargets",
    "outputsMetadata": {
     "0": {
      "height": 543,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "targets = original[['title', 'popularity']]\n",
    "targets = targets.pivot_table(columns='popularity', index='title', aggfunc='size', fill_value=0)\n",
    "targets['pop_diff'] = targets['Popular'] - targets['Unpopular']\n",
    "targets['pop'] = targets['pop_diff']>0\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70455e62-dac9-4ede-b7d7-efe4d78e6d4d",
   "metadata": {},
   "source": [
    "We have our new 'target' dataset were each title (sometimes edition) appears only once. The new target is 'pop' that is True if the number of 'Popular' entries is bigger than the 'Unpopular' ones.\n",
    "\n",
    "Now lets add 2 types of features:\n",
    "- Book features (price, description, category and authors)\n",
    "- Reviews (number, positives vs negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd626f-53a3-44f1-8500-55ade3895099",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 358,
    "lastExecutedAt": 1730551339099,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def unique_concat(values):\n    return ','.join(set(values))\n\n\nbook_feat = books[['title', 'description', 'price', 'categories', 'authors']]\nbook_feat = book_feat.groupby('title').agg({\n    'price': 'mean',\n    'description': ','.join,\n    'authors': unique_concat,\n    'categories': unique_concat\n})\n"
   },
   "outputs": [],
   "source": [
    "def unique_concat(values):\n",
    "    return ','.join(set(values))\n",
    "\n",
    "\n",
    "book_feat = original[['title', 'description', 'price', 'categories', 'authors']]\n",
    "book_feat = book_feat.groupby('title').agg({\n",
    "    'price': 'mean',\n",
    "    'description': ','.join,\n",
    "    'authors': unique_concat,\n",
    "    'categories': unique_concat\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60baae3c-266e-4567-aac5-2c89abc1f0f6",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 19979,
    "lastExecutedAt": 1730551359080,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# One-hot encode the 'authors' and 'categories' columns\nauthors = book_feat['authors'].str.get_dummies(sep=',')\ncategories = book_feat['categories'].str.get_dummies(sep=',')\n\n# Concatenate the original DataFrame with the one-hot encoded columns\nbook_feat = pd.concat([book_feat, authors, categories], axis=1)\n\ndel authors, categories\n\n# Drop the original 'authors' and 'categories' columns\nbook_feat.drop(['authors', 'categories'], inplace=True, axis=1)\n\nbook_feat.head()",
    "outputsMetadata": {
     "0": {
      "height": 235,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "# One-hot encode the 'authors' and 'categories' columns\n",
    "authors = book_feat['authors'].str.get_dummies(sep=',')\n",
    "categories = book_feat['categories'].str.get_dummies(sep=',')\n",
    "\n",
    "# Concatenate the original DataFrame with the one-hot encoded columns\n",
    "book_feat = pd.concat([book_feat, authors, categories], axis=1)\n",
    "\n",
    "del authors, categories\n",
    "\n",
    "# Drop the original 'authors' and 'categories' columns\n",
    "book_feat.drop(['authors', 'categories'], inplace=True, axis=1)\n",
    "\n",
    "book_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8182f-2eb3-48dc-9df1-eb54a0a911b9",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 72,
    "lastExecutedAt": 1730551359152,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# This cell exceeds the cpu/memory available\n\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# \n# # Initialize TfidfVectorizer\n# tfidf_vectorizer = TfidfVectorizer()\n# \n# # Fit and transform the description column\n# X_tfidf = tfidf_vectorizer.fit_transform(book_feat['description'])\n# \n# # Convert to DataFrame\n# tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n# \n# # Concatenate with the original DataFrame\n# book_feat = pd.concat([book_feat.drop('description', axis=1, inplace=True), tfidf_df], axis=1)\n# \n\n# So lets remove the description\nbook_feat=book_feat.drop(columns=['description'], axis=1)"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(book_feat['description'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "book_feat.drop('description', axis=1, inplace=True)\n",
    "\n",
    "book_descs = pd.concat([book_feat, tfidf_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057b1b1-3cc0-4ab9-bcf6-ae550a042d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d5757-1a59-48b8-9656-ae9e8f8d94fb",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 46,
    "lastExecutedAt": 1730551369894,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": ""
   },
   "outputs": [],
   "source": [
    "revs = original[['title', 'review/helpfulness', 'review/summary', 'review/text']]\n",
    "revs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f99f0-6314-4fa7-b6c3-54f96acef549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef9f30-afb7-405b-b6aa-29e6e8f92671",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs[['rev_helps', 'rev_totals']] = revs['review/helpfulness'].str.split('/', expand=True)\n",
    "\n",
    "# Convert the new columns to integers (optional)\n",
    "revs['rev_helps'] = revs['rev_helps'].astype(int)\n",
    "revs['rev_totals'] = revs['rev_totals'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5c4eb-74af-4db1-b02a-7c9926773b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "revs['sentiment'] = revs['review/text'].apply(lambda x: sia.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc8176-3d76-4c11-a0c0-01a5a0578ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e7f9e-50cc-4888-837f-fb1ce025426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs_grouped = revs.groupby('title').agg({\n",
    "    'rev_helps': 'sum',\n",
    "    'rev_totals': 'sum',\n",
    "    'sentiment': 'sum'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fdb503-11c6-4b18-81d6-1f5a5bc4cd02",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 10650,
    "lastExecutedAt": 1730551369848,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "books = pd.merge(book_feat, targets['pop'], left_index=True, right_index=True, how='inner')\nbooks.head()",
    "outputsMetadata": {
     "0": {
      "height": 235,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "books = pd.merge(book_descs, targets['pop'], left_index=True, right_index=True, how='inner')\n",
    "books = pd.merge(books, revs_grouped, left_index=True, right_index=True, how='inner')\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc3351-9a4b-4fa5-b3c7-f90b031f468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books.fillna(value=0)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46707546-1c3d-4fca-ac88-3cb58088a36b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 962,
    "lastExecutedAt": 1730551370856,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX = books.drop('pop', axis=1)\ny = books['pop']\n\n# del books, book_feat, authors, categories, targets\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nrf = RandomForestClassifier(max_depth=5, min_samples_leaf=5)\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\n\nmodel_accuracy=accuracy_score(y_test, y_pred)\nmodel_accuracy"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X = books.drop('pop_y', axis=1)\n",
    "y = books['pop_y']\n",
    "\n",
    "# del books, book_feat, authors, categories, targets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b2c8b-1603-404c-81cd-8676fc30d299",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 962,
    "lastExecutedAt": 1730551370856,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX = books.drop('pop', axis=1)\ny = books['pop']\n\n# del books, book_feat, authors, categories, targets\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nrf = RandomForestClassifier(max_depth=5, min_samples_leaf=5)\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\n\nmodel_accuracy=accuracy_score(y_test, y_pred)\nmodel_accuracy"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=120, max_depth=50, min_samples_split=5, random_state=42, class_weight=\"balanced\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('train_acc: {}'.format(rf.score(X_train, y_train)))\n",
    "print('test_acc: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad89fc-1ecf-49bf-880a-5b601627dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('train_acc: {}'.format(lr.score(X_train, y_train)))\n",
    "print('test_acc: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf0cea-202d-475f-9f52-b7173b731860",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35173908-1d98-4f95-b1fc-17b95ee43b27",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1730551370950,
    "lastExecutedByKernel": "ac32b47d-a2e8-4919-8278-bacfd268ec1a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": ""
   },
   "outputs": [],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdd7310-c46e-4c90-9728-1bc637c3d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc9dee-24ab-4ca6-9263-e2f985a75e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
