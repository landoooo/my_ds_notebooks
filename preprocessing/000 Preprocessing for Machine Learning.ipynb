{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb7c51-22bb-4c35-bc64-f7e758effea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d4c74-73d7-4e6b-a16e-612a3184a688",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Data preprocessing takes place after exploratory data analysis and cleaning\n",
    "\n",
    "We preprocess the data to: \n",
    "- transform the dataset so its suitable for modeling\n",
    "  AND\n",
    "- to improve model performance\n",
    "\n",
    "## 1. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff760c-039a-4f25-a834-29011d9e4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/volunteer_opportunities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee03e9-7289-4749-984f-de0f7e39d8bf",
   "metadata": {},
   "source": [
    "## 2. Inspecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716f5ec-c64d-45cd-a2ee-76e68950fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba63af-3d3b-423e-bfdb-2ddddd896253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73168b8-7566-4dd7-9281-dddfd583e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd341c8e-0c57-49b4-9c03-e5c679dc59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91190ac2-e856-496a-b634-8422cf3f2c30",
   "metadata": {},
   "source": [
    "## 3. Remove Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a5626-4b2f-4429-b40f-4ef36c8a4a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e8214e-ba78-4eab-8d02-e6613b4036b9",
   "metadata": {},
   "source": [
    "- *df.dropna()* -> if only a few rows contain missing data\n",
    "- *df.drop([1,2,3])* -> drops specific rows\n",
    "- *df.drop('column_name', axis=1)* -> drops columns\n",
    "- *df.dropna(subset=['column_name'])* -> drops rows where column_name is empty\n",
    "- *df.dropna(thresh=2)* -> drop columns with 2 or more missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b096385-a5f2-45cf-978c-42231d2a1453",
   "metadata": {},
   "source": [
    "## 4. Typing\n",
    "\n",
    "Pandas infer data types, sometimes incorrectly.\n",
    "\n",
    "The *.info()* method shows the datatype of each column as well as *.dtypes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b21a1dc-d43b-4a30-86b2-8661bb771eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018f8ac-eccf-4246-9487-c5830142f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9afff-40b3-4831-bb4c-f71e3c4aa547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy = pd.DataFrame({'A': ['1.0', '2.0']})\n",
    "df_toy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236b80e-36fd-4c9d-bd5e-d3d025a33bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy['A'] = df_toy['A'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed4e0a-2f81-4de8-990a-b45b15b3b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b1241-b169-476d-800a-09cc45a92725",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047f00c8-6f36-4fa9-8bd6-92e1175544e8",
   "metadata": {},
   "source": [
    "## 5. Training and test split\n",
    "\n",
    "Splitting the dataset into training and test helps: \n",
    "- reducing overfitting\n",
    "- evaluate performance on a holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105344b5-6485-44e7-ad9a-58c247d4304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df.category_desc, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3003b-9feb-4b8f-b744-655e50e71878",
   "metadata": {},
   "source": [
    "**Stratified sampling** helps keeping all the classes represented in the target test dataset when it is very imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab813734-d378-4a7e-86af-2a7282ff8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df.category_desc, test_size=0.2, random_state=42, stratify=df.category_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39dbcf-ccb1-4777-a1be-d619a93dc7db",
   "metadata": {},
   "source": [
    "## 6. Standardization\n",
    "\n",
    "**Standardization** is the process to transform **continuous** data to appear **normally distributed**\n",
    "\n",
    "Many of the sklearn models assume normally distributed data. Using non-normal data could bias the models.\n",
    "\n",
    "Standardization is required: \n",
    "- When we are using a model in linera space (like KNN, linear regression or KMeans)\n",
    "- When the dataset features have high variance\n",
    "- Features are on different scales (for instance number of bedrooms vs price)\n",
    "\n",
    "## 6.1. Log Normalization\n",
    "\n",
    "Useful for features with high variance\n",
    "\n",
    "Applies logarithm transformation\n",
    "\n",
    "Natural log using the constant $e$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2120a02-f4ff-442e-955c-4fd7b94bdf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c\n",
    "df['logs'] = np.log(df['values'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0e9394-08f8-443d-8368-9789b2a12925",
   "metadata": {},
   "source": [
    "Captures relative changes, the magnitude of change, and keeps everything positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4a2250-ff81-4b8b-a038-6c92b1b50a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:04:59.939936Z",
     "iopub.status.busy": "2024-08-27T12:04:59.938822Z",
     "iopub.status.idle": "2024-08-27T12:04:59.953136Z",
     "shell.execute_reply": "2024-08-27T12:04:59.951393Z",
     "shell.execute_reply.started": "2024-08-27T12:04:59.939891Z"
    }
   },
   "source": [
    "## 6.2. Scaling \n",
    "\n",
    "Features on different scales\n",
    "\n",
    "Model with linear characteristics\n",
    "\n",
    "Center features around 0 and transform variance to 1\n",
    "\n",
    "Transforms to approximately normal distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfda24c-85f2-4a9e-bc52-47a14faff13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'col1': [0.1, 0.2, 0.3],\n",
    "    'col2': [10, 5.2, 8.3],\n",
    "    'col3': [120, 100.2, 89.3]\n",
    "})\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1704d-0ed6-4ec5-8770-818ac6f4a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bafb2f6-24ee-41d5-9de4-5125a71ae4dc",
   "metadata": {},
   "source": [
    "## 6. Standardized data and modeling\n",
    "\n",
    "Its important to split the data before preprocessing the data, otherwise there would be a **data leakage** and the test data could have been showed somehow to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e857d4a-1f51-458c-afe3-ae83823b114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5dd8f8-0b2e-40f5-ad14-ba9214ed930a",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering\n",
    "\n",
    "**Feature engineering** is the creation of new features from existing ones\n",
    "\n",
    "It adds information to the dataset that can improve the performance of the model or add insight into relationships between features\n",
    "\n",
    "Before doing feature engineering we must understand our data first.\n",
    "\n",
    "Feature engineering is highly dependent on the dataset we have at hand\n",
    "\n",
    "Typical feature engineering scenarios are extracting features from free text, or parsing strings containing dates.\n",
    "\n",
    "## 8. Encoding categorical variables\n",
    "\n",
    "Sklearn models requires numerical input only. If there is any categorical data, it has to be encoded.\n",
    "\n",
    "### 8.1 Encoding variables with 2 different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b1f24b-0743-4f99-ba43-a2672956692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'user': [1,2,3, 4],\n",
    "    'subscribed': ['y','y','n', 'y'],\n",
    "    'fav_color': ['yellow', 'orange', 'orange', 'green']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ecfce-5cba-4fec-a09e-b7ab2db643ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.subscribed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dfaa7f-2d37-4433-904f-4935503adbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas way\n",
    "df.subscribed.apply(lambda x: 1 if x=='y' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f9950-6f33-4d74-86a1-8665947a909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SciKit Learn way \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit_transform(df.subscribed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed210c04-4aba-4987-9136-26b2ff5a962e",
   "metadata": {},
   "source": [
    "### 8.2 One Hot Encoding\n",
    "\n",
    "Applies when the variable has more than 2 different values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506e115-14b5-4d61-a0be-29120ef81c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df.fav_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960a783-b27c-4315-91da-2d4ef9c9fc0d",
   "metadata": {},
   "source": [
    "## 9. Engineering Numerical Features\n",
    "\n",
    "Examples of reducing dimensionality: Means or medians of several variables, extracting month or week from dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57300bc-8958-4354-93d5-aef570e7f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "volunteer = pd.read_csv('../data/volunteer_opportunities.csv')\n",
    "volunteer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83616549-b3c4-439d-bce8-1522e0f93fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "volunteer.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2d0b5-5dab-4688-af89-d55cadcccea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "volunteer[\"start_date_converted\"] = pd.to_datetime(volunteer[\"start_date_date\"])\n",
    "volunteer[\"start_date_month\"] = volunteer['start_date_converted'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd3162-8dd3-42e7-8a1c-cd2e3a1da132",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(volunteer[['start_date_converted', 'start_date_month']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff24d2a1-3db5-4b5b-b128-3b1070a71d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T13:19:41.950489Z",
     "iopub.status.busy": "2024-08-27T13:19:41.949710Z",
     "iopub.status.idle": "2024-08-27T13:19:41.958589Z",
     "shell.execute_reply": "2024-08-27T13:19:41.956069Z",
     "shell.execute_reply.started": "2024-08-27T13:19:41.950446Z"
    }
   },
   "source": [
    "## 10. Engineering Text Features\n",
    "\n",
    "### 10.1. Extraction\n",
    "\n",
    "Regular expressions is code that identify patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bfb966-ba74-45ab-8d12-5e316c4cd496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "my_string = 'temperature:75.6 F'\n",
    "temp = re.search('\\d+\\.\\d+', my_string)\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad178ba1-d139-4861-a2ea-875317692cc7",
   "metadata": {},
   "source": [
    "If we are working with text it could be helpful to model it in some way.\n",
    "\n",
    "**TF/IDF** (Term Frequency/Inverse Document Frequency) Vectorizes words based upon importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa7edb-5b63-4b6b-9f15-ef72929516fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "volunteer.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42753ade-025f-4241-8749-956967722238",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer()\n",
    "text_tfidf = tfidf_vec.fit_transform(volunteer.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3730ea-1de4-46d1-9def-1838ff6a960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef769d56-185d-41c1-9adb-c64eaf399dc7",
   "metadata": {},
   "source": [
    "## 11. Feature Selection \n",
    "\n",
    "Feature selection is the step where some features are picked from the feature set to be used for modeling.\n",
    "\n",
    "It doesnt create new features.\n",
    "\n",
    "The goal is to improve models performance\n",
    "\n",
    "There are many ways to perform feature selection, some are automated.\n",
    "\n",
    "Reducing noise, removing features strongly statistically correlated, reducing overall variance...\n",
    "\n",
    "### 11.1. Removing redundant features \n",
    "\n",
    "- Remove noisy features (almost the same information)\n",
    "- Remove highly correlated features. The Pearson correlation coefficient is handy for this.\n",
    "- Remove duplicated features (often created during feature engineering)\n",
    "- Remove features with repeated information (for instance latlon and city)\n",
    "- Remove the original values used to compute an aggregated value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b74a85-a418-4cfe-be61-7b2216bc862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.DataFrame({\n",
    "    'user': [-1,2,3, 4],\n",
    "    'other': [2, 1, 3, -1],\n",
    "    'another': [25,-24,2,1]\n",
    "})\n",
    "\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a85dc-2e5e-4139-bf5c-12ee57b7fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece89dee-291b-4276-9cc4-b1cde4b70d2e",
   "metadata": {},
   "source": [
    "### 11.2. Selecting features using text vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc908ec-92a3-4972-9424-2b3ed8136be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking = pd.read_json('../data/hiking.json')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfid_vec = TfidfVectorizer()\n",
    "\n",
    "tfid_text = tfid_vec.fit_transform(hiking.Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b04a75-1a72-4120-a549-f2fcecd2d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d90256-9e46-4a56-87f6-7cd4a847540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_text[3].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f448e29-5e20-4e13-9f52-ba84fc5cc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_text[3].indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ab109-2cd2-4274-8dde-84ad480867fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {v:k for k,v in tfidf_vec.vocabulary_.items()}\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3a684-fd05-42b3-ada5-47a4e4a1ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_row = dict(zip(text_tfidf[3].indices, text_tfidf[3].data))\n",
    "zipped_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d592b-aa6b-4505-b46f-1046d4684eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in the rest of the arguments\n",
    "def return_weights(vocab, original_vocab, vector, vector_index, top_n):\n",
    "    zipped = dict(zip(vector[vector_index].indices, vector[vector_index].data))\n",
    "    \n",
    "    # Transform that zipped dict into a series\n",
    "    zipped_series = pd.Series({vocab[i]:zipped[i] for i in vector[vector_index].indices})\n",
    "    \n",
    "    # Sort the series to pull out the top n weighted words\n",
    "    zipped_index = zipped_series.sort_values(ascending=False)[:top_n].index\n",
    "    return [original_vocab[i] for i in zipped_index]\n",
    "\n",
    "# Print out the weighted words\n",
    "print(return_weights(vocab, tfidf_vec.vocabulary_, tfid_text, 8, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b03c54-0373-4a2e-a098-21030afaf4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_filter(vocab, original_vocab, vector, top_n):\n",
    "    filter_list = []\n",
    "    for i in range(0, vector.shape[0]):\n",
    "    \n",
    "        # Call the return_weights function and extend filter_list\n",
    "        filtered = return_weights(vocab, original_vocab, vector, i, top_n)\n",
    "        filter_list.extend(filtered)\n",
    "        \n",
    "    # Return the list in a set, so we don't get duplicate word indices\n",
    "    return set(filter_list)\n",
    "\n",
    "# Call the function to get the list of word indices\n",
    "filtered_words = words_to_filter(vocab, tfidf_vec.vocabulary_, text_tfidf, 3)\n",
    "\n",
    "# Filter the columns in text_tfidf to only those in filtered_words\n",
    "filtered_text = tfid_text[:, list(filtered_words)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6db2a3-9b3d-4595-8f69-346d03d6de18",
   "metadata": {},
   "source": [
    "## 12. Dimensionality Reduction and PCA\n",
    "\n",
    "Its an unsupervised learning method\n",
    "\n",
    "Combines/decomposes a feature space. It shrinks the number of features on the feature space.\n",
    "\n",
    "Dimensionality reduction is a feature extraction method since the data is transformed into new and different features.\n",
    "\n",
    "PCA stands for principal component analysis and uses a linear transformation to project features into a linear space where they can be completely uncorrelated.\n",
    "\n",
    "While the feature space is reduce, the variance is captured in a meaningful way by combining features into components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da416c-e201-43aa-be24-64285c94392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df_pca = pd.DataFrame({\n",
    "    'user': [-1,2,3, 4],\n",
    "    'other': [2, 1, 3, -1],\n",
    "    'trololo': [20, 11, -53, 21],\n",
    "    'another': [25,-24,2,1]\n",
    "})\n",
    "\n",
    "pca = PCA()\n",
    "df_pca = pca.fit_transform(df_pca)\n",
    "df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a10ed6-62bc-4992-b63d-846c78e25594",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d836e-0435-4c3b-8e10-a20c2230a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418c62cd-5e84-4641-822c-9190e948c8af",
   "metadata": {},
   "source": [
    "PCA has though some caveats: \n",
    "- Its components are difficult to interpret\n",
    "- It fits better right at the end of the preprocessing journey. It would be hard to do anything with the pca components after its transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab7518-12e3-4a8d-80a3-07a11a90e75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
